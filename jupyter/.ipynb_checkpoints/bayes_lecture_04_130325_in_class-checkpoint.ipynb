{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:35.573478Z",
     "iopub.status.busy": "2021-04-16T19:35:35.572460Z",
     "iopub.status.idle": "2021-04-16T19:35:36.312737Z",
     "shell.execute_reply": "2021-04-16T19:35:36.313087Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import set_pyplot_params\n",
    "set_pyplot_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will introduce the [Poisson process](https://en.wikipedia.org/wiki/Poisson_point_process), which is a model used to describe events that occur at random intervals.\n",
    "As an example of a Poisson process, we'll model goal-scoring in football (not American football).\n",
    "We'll use goals scored in a game to estimate the parameter of a Poisson process; then we'll use the posterior distribution to make predictions.\n",
    "\n",
    "And we'll solve The World Cup Problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The World Cup Problem\n",
    "\n",
    "In the 2018 FIFA World Cup final, France defeated Croatia 4 goals to 2.  Based on this outcome:\n",
    "\n",
    "1. How confident should we be that France is the better team?\n",
    "\n",
    "2. If the same teams played again, what is the chance France would win again?\n",
    "\n",
    "To answer these questions, we have to make some modeling decisions.\n",
    "\n",
    "* First, we'll assume that for any team against another team there is some unknown goal-scoring rate, measured in goals per game, which we'll denote with the Python variable `lam` or the Greek letter $\\lambda$.\n",
    "\n",
    "* Second, we'll assume that a goal is equally likely during any minute of a game.  So, in a 90 minute game, the probability of scoring during any minute is $\\lambda/90$.\n",
    "\n",
    "* Third, we'll assume that a team never scores twice during the same minute.\n",
    "\n",
    "Of course, none of these assumptions is completely true in the real world, but they are reasonable simplifications.\n",
    "As George Box said, \"All models are wrong; some are useful.\"\n",
    "(https://en.wikipedia.org/wiki/All_models_are_wrong).\n",
    "\n",
    "In this case, the model is useful because if these assumptions are \n",
    "true, at least roughly, the number of goals scored in a game follows a Poisson distribution, at least roughly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Poisson Distribution\n",
    "\n",
    "If the number of goals scored in a game follows a [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution) with a goal-scoring rate, $\\lambda$, the probability of scoring $k$ goals is\n",
    "\n",
    "$$\\lambda^k \\exp(-\\lambda) ~/~ k!$$\n",
    "\n",
    "for any non-negative value of $k$.\n",
    "\n",
    "SciPy provides a `poisson` object that represents a Poisson distribution.\n",
    "We can create one with $\\lambda=1.4$ like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.320352Z",
     "iopub.status.busy": "2021-04-16T19:35:36.319569Z",
     "iopub.status.idle": "2021-04-16T19:35:36.323543Z",
     "shell.execute_reply": "2021-04-16T19:35:36.324079Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The result is an object that represents a \"frozen\" random variable and provides `pmf`, which evaluates the probability mass function of the Poisson distribution.\n",
    "\n",
    "\n",
    "- `frozen` means that the parameter $\\lambda$ is fixed at 1.4 and we can use methods like `.pmf()`, `.cdf()`, `.rvs()` without needing to specify $\\lambda$ again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.329080Z",
     "iopub.status.busy": "2021-04-16T19:35:36.328350Z",
     "iopub.status.idle": "2021-04-16T19:35:36.331701Z",
     "shell.execute_reply": "2021-04-16T19:35:36.332267Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This result implies that if the average goal-scoring rate is 1.4 goals per game, the probability of scoring 4 goals in a game is about 4%.\n",
    "\n",
    "\n",
    "- We'll use the following function to make a `Pmf` that represents a Poisson distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.338086Z",
     "iopub.status.busy": "2021-04-16T19:35:36.337399Z",
     "iopub.status.idle": "2021-04-16T19:35:36.339498Z",
     "shell.execute_reply": "2021-04-16T19:35:36.338953Z"
    }
   },
   "outputs": [],
   "source": [
    "from empiricaldist import Pmf\n",
    "\n",
    "def make_poisson_pmf(lam, qs):\n",
    "    \"\"\"Make a Pmf of a Poisson distribution.\"\"\"\n",
    "    ps = poisson(lam).pmf(qs)\n",
    "    pmf = Pmf(ps, qs)\n",
    "    pmf.normalize()\n",
    "    return pmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `make_poisson_pmf` takes as parameters the goal-scoring rate, `lam`, and an array of quantities, `qs`, where it should evaluate the Poisson PMF.  It returns a `Pmf` object.\n",
    "\n",
    "- For example, here's the distribution of goals scored for `lam=1.4`, computed for values of `k` from 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.346180Z",
     "iopub.status.busy": "2021-04-16T19:35:36.345152Z",
     "iopub.status.idle": "2021-04-16T19:35:36.351746Z",
     "shell.execute_reply": "2021-04-16T19:35:36.351317Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.357426Z",
     "iopub.status.busy": "2021-04-16T19:35:36.356638Z",
     "iopub.status.idle": "2021-04-16T19:35:36.360496Z",
     "shell.execute_reply": "2021-04-16T19:35:36.360974Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import decorate\n",
    "\n",
    "def decorate_goals(title=''):\n",
    "    decorate(xlabel='Number of goals',\n",
    "        ylabel='PMF',\n",
    "        title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.365999Z",
     "iopub.status.busy": "2021-04-16T19:35:36.365195Z",
     "iopub.status.idle": "2021-04-16T19:35:36.806363Z",
     "shell.execute_reply": "2021-04-16T19:35:36.805860Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The most likely outcomes are 0, 1, and 2; higher values are possible but increasingly unlikely.\n",
    "Values above 7 are negligible.\n",
    "\n",
    "- This distribution shows that if we know the goal scoring rate, we can predict the number of goals.\n",
    "\n",
    "\n",
    "- Now let's turn it around: given a number of goals, what can we say about the goal-scoring rate?\n",
    "\n",
    "\n",
    "- To answer that, we need to think about the prior distribution of `lam`, which represents the range of possible values and their probabilities before we see the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gamma Distribution\n",
    "\n",
    "- If you have ever seen a soccer game, you have some information about `lam`.  \n",
    "\n",
    "- In most games, teams score a few goals each.  In rare cases, a team might score more than 5 goals, but they almost never score more than 10.\n",
    "\n",
    "\n",
    "- Using [data from previous World Cups](https://www.statista.com/statistics/269031/goals-scored-per-game-at-the-fifa-world-cup-since-1930/), we estimate that ***each team*** scores about 1.4 goals per game, on average.  So we'll set the mean of `lam` to be 1.4.\n",
    "\n",
    "\n",
    "- For a good team against a bad one, we expect `lam` to be higher; for a bad team against a good one, we expect it to be lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To model the distribution of goal-scoring rates, i.e. $\\gamma$, we'll use a [gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution), which we chose because:\n",
    "\n",
    "\n",
    "1. The goal scoring rate is continuous and non-negative, and the gamma distribution is appropriate for this kind of quantity.\n",
    "\n",
    "2. The gamma distribution has only one parameter, `alpha`, which is the mean.  So it's easy to construct a gamma distribution with the mean we want.\n",
    "\n",
    "3. As we'll see, the shape of the gamma distribution is a reasonable choice, given what we know about soccer.\n",
    "\n",
    "\n",
    "- And there's one more reason, which I will reveal in <<_ConjugatePriors>>.\n",
    "\n",
    "\n",
    "- SciPy provides `gamma`, which creates an object that represents a gamma distribution.\n",
    "And the `gamma` object provides provides `pdf`, which evaluates the  **probability density function** (PDF) of the gamma distribution.\n",
    "\n",
    "\n",
    "- Here's how we use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.811180Z",
     "iopub.status.busy": "2021-04-16T19:35:36.810595Z",
     "iopub.status.idle": "2021-04-16T19:35:36.812206Z",
     "shell.execute_reply": "2021-04-16T19:35:36.812559Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter, `alpha`, is the mean of the distribution.\n",
    "The `qs` are possible values of `lam` between 0 and 10.\n",
    "The `ps` are **probability densities**, which we can think of as unnormalized probabilities.\n",
    "\n",
    "To normalize them, we can put them in a `Pmf` and call `normalize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.817622Z",
     "iopub.status.busy": "2021-04-16T19:35:36.816921Z",
     "iopub.status.idle": "2021-04-16T19:35:36.820318Z",
     "shell.execute_reply": "2021-04-16T19:35:36.819842Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall that the result of the script above, 9.88936, is the original sum of the unnormalized \"probabilities\" before normalizing the PMF. \n",
    "\n",
    "- After normalization, the sum is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a discrete approximation of a gamma distribution.\n",
    "Here's what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.824445Z",
     "iopub.status.busy": "2021-04-16T19:35:36.823630Z",
     "iopub.status.idle": "2021-04-16T19:35:36.826395Z",
     "shell.execute_reply": "2021-04-16T19:35:36.825832Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decorate_rate(title=''):\n",
    "    decorate(xlabel='Goal scoring rate (lam)',\n",
    "        ylabel='PMF',\n",
    "        title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.861338Z",
     "iopub.status.busy": "2021-04-16T19:35:36.850188Z",
     "iopub.status.idle": "2021-04-16T19:35:36.973653Z",
     "shell.execute_reply": "2021-04-16T19:35:36.974165Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prior.plot(ls='--', label='prior', color='C5')\n",
    "decorate_rate(r'Prior distribution of $\\lambda$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution represents our ***prior knowledge*** about goal scoring: `lam` is usually less than 2, occasionally as high as 6, and seldom higher than that.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "And we can confirm that the mean is about 1.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.977679Z",
     "iopub.status.busy": "2021-04-16T19:35:36.977270Z",
     "iopub.status.idle": "2021-04-16T19:35:36.981785Z",
     "shell.execute_reply": "2021-04-16T19:35:36.981415Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, reasonable people could disagree about the details of the prior, but this is good enough to get started.  Let's do an update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Update\n",
    "\n",
    "Suppose you are given the goal-scoring rate, $\\lambda$, and asked to compute the probability of scoring a number of goals, $k$.  That is precisely the question we answered by computing the Poisson PMF.\n",
    "\n",
    "For example, if $\\lambda$ is 1.4, the probability of scoring 4 goals in a game is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.986101Z",
     "iopub.status.busy": "2021-04-16T19:35:36.985682Z",
     "iopub.status.idle": "2021-04-16T19:35:36.990357Z",
     "shell.execute_reply": "2021-04-16T19:35:36.989881Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we are have an array of possible values for $\\lambda$; we can compute the likelihood of the data for each hypothetical value of `lam`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.994726Z",
     "iopub.status.busy": "2021-04-16T19:35:36.994093Z",
     "iopub.status.idle": "2021-04-16T19:35:36.996133Z",
     "shell.execute_reply": "2021-04-16T19:35:36.995693Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And that's all we need to do the update.\n",
    "\n",
    "- To get the posterior distribution, we multiply the prior by the likelihoods we just computed and normalize the result.\n",
    "\n",
    "\n",
    "- The following function encapsulates these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:36.999424Z",
     "iopub.status.busy": "2021-04-16T19:35:36.999004Z",
     "iopub.status.idle": "2021-04-16T19:35:37.000604Z",
     "shell.execute_reply": "2021-04-16T19:35:37.000963Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_poisson(pmf, data):\n",
    "    \"\"\"Update Pmf with a Poisson likelihood.\"\"\"\n",
    "    k = data\n",
    "    lams = pmf.qs\n",
    "    likelihood = poisson(lams).pmf(k)\n",
    "    pmf *= likelihood\n",
    "    pmf.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter is the prior; the second is the number of goals.\n",
    "\n",
    "In the example, France scored 4 goals, so I'll make a copy of the prior and update it with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:37.006206Z",
     "iopub.status.busy": "2021-04-16T19:35:37.005520Z",
     "iopub.status.idle": "2021-04-16T19:35:37.007211Z",
     "shell.execute_reply": "2021-04-16T19:35:37.007583Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the posterior distribution looks like, along with the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:37.028551Z",
     "iopub.status.busy": "2021-04-16T19:35:37.028101Z",
     "iopub.status.idle": "2021-04-16T19:35:37.185307Z",
     "shell.execute_reply": "2021-04-16T19:35:37.184888Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prior.plot(ls='--', label='prior', color='C5')\n",
    "\n",
    "\n",
    "decorate_rate(r'Posterior distribution of $\\lambda$ for France')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data, `k=4`, makes us think higher values of `lam` are more likely and lower values are less likely.  So the posterior distribution is shifted to the right.\n",
    "\n",
    "Let's do the same for Croatia (that scored 2 goals in the final):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:37.190240Z",
     "iopub.status.busy": "2021-04-16T19:35:37.189712Z",
     "iopub.status.idle": "2021-04-16T19:35:37.191717Z",
     "shell.execute_reply": "2021-04-16T19:35:37.192161Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:37.231183Z",
     "iopub.status.busy": "2021-04-16T19:35:37.225303Z",
     "iopub.status.idle": "2021-04-16T19:35:37.342248Z",
     "shell.execute_reply": "2021-04-16T19:35:37.341893Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prior.plot(ls='--', label='prior', color='C5')\n",
    "croatia.plot(label='Croatia posterior', color='C0')\n",
    "\n",
    "decorate_rate(r'Posterior distribution of $\\lambda$ for Croatia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the posterior means for these distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:37.345387Z",
     "iopub.status.busy": "2021-04-16T19:35:37.344949Z",
     "iopub.status.idle": "2021-04-16T19:35:37.348895Z",
     "shell.execute_reply": "2021-04-16T19:35:37.349408Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The mean of the prior distribution is about 1.4.\n",
    "\n",
    "- After Croatia scores 2 goals, their posterior mean is 1.7, which is near the midpoint of the prior and the data.\n",
    "\n",
    "- Likewise after France scores 4 goals, their posterior mean is 2.7.\n",
    "\n",
    "\n",
    "- These results are typical of a Bayesian update: ***the location of the posterior distribution is a compromise between the prior and the data***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of Superiority\n",
    "\n",
    "- Now that we have a posterior distribution for each team, we can answer the first question: How confident should we be that France is the better team?\n",
    "\n",
    "\n",
    "- In the model, \"better\" means having a higher goal-scoring rate against the opponent.  We can use the posterior distributions to compute the probability that a random value drawn from France's distribution exceeds a value drawn from Croatia's.\n",
    "\n",
    "\n",
    "- One way to do that is to enumerate all pairs of values from the two distributions, adding up the total probability that one value exceeds the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:37.352893Z",
     "iopub.status.busy": "2021-04-16T19:35:37.352483Z",
     "iopub.status.idle": "2021-04-16T19:35:37.355738Z",
     "shell.execute_reply": "2021-04-16T19:35:37.355251Z"
    }
   },
   "outputs": [],
   "source": [
    "def prob_gt(pmf1, pmf2):\n",
    "    \"\"\"Compute the probability of superiority.\"\"\"\n",
    "    total = 0\n",
    "    for q1, p1 in pmf1.items():\n",
    "        for q2, p2 in pmf2.items():\n",
    "            if q1 > q2:\n",
    "                total += p1 * p2\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:37.361765Z",
     "iopub.status.busy": "2021-04-16T19:35:37.361299Z",
     "iopub.status.idle": "2021-04-16T19:35:37.363760Z",
     "shell.execute_reply": "2021-04-16T19:35:37.364124Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pmf` provides a function that does the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:37.367610Z",
     "iopub.status.busy": "2021-04-16T19:35:37.366920Z",
     "iopub.status.idle": "2021-04-16T19:35:37.370347Z",
     "shell.execute_reply": "2021-04-16T19:35:37.370715Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The results are slightly different because `Pmf.prob_gt` uses array operators rather than `for` loops.\n",
    "\n",
    "\n",
    "- Either way, the result is close to 75%.  So, on the basis of one game, we have moderate confidence that France is actually the better team.\n",
    "\n",
    "\n",
    "- Of course, we should remember that this result is based on the assumption that the goal-scoring rate is constant.\n",
    "In reality, if a team is down by one goal, they might play more aggressively toward the end of the game, making them more likely to score, but also more likely to give up an additional goal.\n",
    "\n",
    "\n",
    "- As always, the results are only as good as the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Rematch\n",
    "\n",
    "- Now we can take on the second question: If the same teams played again, what is the chance Croatia would win?\n",
    "\n",
    "- To answer this question, we'll generate the \"posterior predictive distribution\", which is the number of goals we expect a team to score.\n",
    "\n",
    "\n",
    "- If we knew the goal scoring rate, `lam`, the distribution of goals would be a Poisson distribution with parameter `lam`.\n",
    "\n",
    "- Since we don't know `lam`, the distribution of goals is a mixture of a Poisson distributions with different values of `lam`.\n",
    "\n",
    "\n",
    "- First we'll generate a sequence of `Pmf` objects, one for each value of `lam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:37.411054Z",
     "iopub.status.busy": "2021-04-16T19:35:37.394398Z",
     "iopub.status.idle": "2021-04-16T19:35:37.494790Z",
     "shell.execute_reply": "2021-04-16T19:35:37.494245Z"
    }
   },
   "outputs": [],
   "source": [
    "pmf_seq = [make_poisson_pmf(lam, goals) \n",
    "           for lam in prior.qs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows what these distributions look like for a few values of `lam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T19:35:37.518985Z",
     "iopub.status.busy": "2021-04-16T19:35:37.518453Z",
     "iopub.status.idle": "2021-04-16T19:35:38.081641Z",
     "shell.execute_reply": "2021-04-16T19:35:38.082938Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i, index in enumerate([10, 20, 30, 40]):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    lam = prior.qs[index]\n",
    "    pmf = pmf_seq[index]\n",
    "    pmf.bar(label=f'$\\lambda$ = {lam}', color='C3')\n",
    "    decorate_goals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The predictive distribution is a mixture of these `Pmf` objects, weighted with the posterior probabilities.\n",
    "\n",
    "\n",
    "- We can use `make_mixture` from <<_GeneralMixtures>> to compute this mixture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the posterior predictive distribution for the number of goals France would score in a rematch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define possible goal counts (D values)\n",
    "# Possible number of goals (0 to 9)\n",
    "\n",
    "\n",
    "# Initialize the posterior predictive distribution\n",
    "\n",
    "\n",
    "# Loop over each lambda value in the posterior\n",
    "for lam, p_lambda in zip(france.qs, france.ps):  # Iterate over posterior (lambda values and probabilities)\n",
    "    pred_france += p_lambda * poisson.pmf(goal_counts, lam)  # Weighted sum of Poisson distributions\n",
    "\n",
    "# Normalize (optional, should already sum to 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(goal_counts, pred_france, color='C3', label=\"France\")\n",
    "plt.xlabel(\"Number of goals\")\n",
    "plt.ylabel(\"PMF\")\n",
    "plt.title(\"Posterior Predictive Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution represents two sources of uncertainty: we don't know the actual value of `lam`, and even if we did, we would not know the number of goals in the next game.\n",
    "\n",
    "Here's the predictive distribution for Croatia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the posterior predictive distribution\n",
    "pred_croatia = np.zeros_like(goal_counts, dtype=float)\n",
    "\n",
    "# Loop over each lambda value in the posterior\n",
    "for lam, p_lambda in zip(croatia.qs, croatia.ps):  # Iterate over posterior (lambda values and probabilities)\n",
    "    pred_croatia += p_lambda * poisson.pmf(goal_counts, lam)  # Weighted sum of Poisson distributions\n",
    "\n",
    "# Normalize (optional, should already sum to 1)\n",
    "pred_croatia /= pred_croatia.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(goal_counts, posterior_pred_croatia, color='C3', label=\"Croatia\")\n",
    "plt.xlabel(\"Number of goals\")\n",
    "plt.ylabel(\"PMF\")\n",
    "plt.title(\"Posterior Predictive Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the difference between a Posterior distribution and a Posterior Predictive distribution?\n",
    "\n",
    "#### 1. Posterior Distribution $P(\\lambda \\mid D)$\n",
    "\n",
    "The **posterior distribution** represents our **updated belief** about the **parameter** $\\lambda$ (e.g., a team's goal-scoring rate) after observing data $D$.\n",
    "\n",
    "It is computed using **Bayes' Rule**:\n",
    "\n",
    "$$\n",
    "P(\\lambda \\mid D) = \\frac{P(D \\mid \\lambda) P(\\lambda)}{P(D)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $P(\\lambda)$ is the **prior** (belief before data).\n",
    "- $P(D \\mid \\lambda)$ is the **likelihood** (how likely the data is given $\\lambda$).\n",
    "- $P(D)$ is the **marginal likelihood** (normalizing factor).\n",
    "\n",
    "The **posterior** gives us a **distribution over possible values of** $\\lambda$ **based on observed data**.\n",
    "\n",
    "#### **Example: Posterior for France’s Goal-Scoring Rate $\\lambda$**\n",
    "- Before observing data, we may assume $\\lambda \\sim \\text{Gamma}(1.4)$.\n",
    "- After observing **France scores 4 goals**, we update our belief to obtain a **posterior distribution over** $\\lambda$.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Posterior Predictive Distribution $P(D_{\\text{new}} \\mid D)$\n",
    "\n",
    "The **posterior predictive distribution** describes **what we expect future data to look like**, given:\n",
    "\n",
    "- The **posterior distribution** of $\\lambda$.\n",
    "- The **likelihood function**.\n",
    "\n",
    "It is computed by **integrating out** $\\lambda$:\n",
    "\n",
    "$$\n",
    "P(D_{\\text{new}} \\mid D) = \\int P(D_{\\text{new}} \\mid \\lambda) P(\\lambda \\mid D) d\\lambda\n",
    "$$\n",
    "\n",
    "This means we:\n",
    "\n",
    "1. **Sample** $\\lambda$ from the **posterior** $P(\\lambda \\mid D)$.\n",
    "2. **Use** $\\lambda$ to generate **new predictions** using the likelihood $P(D_{\\text{new}} \\mid \\lambda)$.\n",
    "\n",
    "#### **Example: Posterior Predictive for Future Goals**\n",
    "- Suppose we now want to **predict how many goals France will score in a rematch**.\n",
    "- Since **$\\lambda$ is uncertain**, we **don’t use a single Poisson distribution** $\\text{Poisson}(\\lambda)$.\n",
    "- Instead, we **average over all possible $\\lambda$ values** weighted by their **posterior probability**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these distributions to compute the **probability that France wins, loses, or ties** the rematch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pmf objects for comparison\n",
    "pred_france_pmf = Pmf(pred_france, goal_counts)\n",
    "pred_croatia_pmf = Pmf(pred_croatia, goal_counts)\n",
    "\n",
    "# Compute probabilities\n",
    "win = Pmf.prob_gt(pred_france_pmf, pred_croatia_pmf)\n",
    "lose = Pmf.prob_lt(pred_france_pmf, pred_croatia_pmf)\n",
    "tie = Pmf.prob_eq(pred_france_pmf, pred_croatia_pmf)\n",
    "\n",
    "# Compute final win probability\n",
    "win_probability = win + tie / 2\n",
    "\n",
    "# Print the results\n",
    "print(\"France's Probability of Winning:\", win_probability)\n",
    "print(\"Probability France loses:\", lose)\n",
    "print(\"Probability of a tie:\", tie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that France wins half of the ties, their chance of winning the rematch is about 65%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit lower than their probability of superiority, which is 75%. And that makes sense, because we are less certain about the outcome of a single game than we are about the goal-scoring rates.\n",
    "Even if France is the better team, they might lose the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* If a system satisfies the assumptions of a Poisson model, the number of events in a period of time follows a Poisson distribution, which is a discrete distribution with integer quantities from 0 to infinity. In practice, we can usually ignore low-probability quantities above a finite limit.\n",
    "\n",
    "* For the prior distribution of $\\lambda$, we used a gamma distribution, which is a continuous distribution with quantities from 0 to infinity, but we approximated it with a discrete, bounded PMF. The gamma distribution has one parameter, denoted $\\alpha$ or `alpha`, which is also its mean.\n",
    "\n",
    "- We chose the gamma distribution because the shape is consistent with our background knowledge about goal-scoring rates.\n",
    "\n",
    "- There are other distributions we could have used; however, we will see in <<_ConjugatePriors>> that the gamma distribution can be a particularly good choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjugate Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_pyplot_params\n",
    "set_pyplot_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Earlier we have used what's called grid approximations to solve some problems.\n",
    "\n",
    "\n",
    "- One of the goals has been to show that this approach is sufficient to solve many real-world problems.\n",
    "\n",
    "- And it's a good place to start because it shows clearly how the methods work.\n",
    "\n",
    "\n",
    "- However, as we increase the number of parameters, the number of points in the grid grows (literally) exponentially.\n",
    "\n",
    "- With more than 3-4 parameters, grid methods become impractical.\n",
    "\n",
    "\n",
    "- Here, we will discuss an alternative **conjugate priors**.\n",
    "\n",
    "\n",
    "- We'll start with the World Cup problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The World Cup Problem Revisited\n",
    "\n",
    "- Previously, we solved the World Cup problem using a Poisson process to model goals in a soccer game as random events that are equally likely to occur at any point during a game.\n",
    "\n",
    "\n",
    "- We used a gamma distribution to represent the prior distribution of $\\lambda$, the goal-scoring rate.  And we used a Poisson distribution to compute the probability of $k$, the number of goals scored.\n",
    "\n",
    "\n",
    "- Here's a gamma object that represents the prior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "\n",
    "alpha = 1.4\n",
    "dist = gamma(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's a grid approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import pmf_from_dist\n",
    "\n",
    "lams = np.linspace(0, 10, 101)\n",
    "prior = pmf_from_dist(dist, lams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the likelihood of scoring 4 goals for each possible value of `lam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So far, this should be familiar.\n",
    "\n",
    "- Now we'll solve the same problem using the **conjugate prior**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Conjugate Prior\n",
    "\n",
    "- One reason we earlier chose the gamma distribution is that it is the \"conjugate prior\" of the Poisson distribution, so-called because the two distributions are connected or coupled, which is what \"conjugate\" means.\n",
    "\n",
    "\n",
    "- In the next section we'll show *how* they are connected, but first we'll look at the consequence of this connection, which is that there is a remarkably simple way to compute the posterior distribution.\n",
    "\n",
    "\n",
    "- However, in order to demonstrate it, we have to switch from the one-parameter version of the gamma distribution to the two-parameter version.  Since the first parameter is called `alpha`, you might guess that the second parameter is called `beta`.\n",
    "\n",
    "\n",
    "- The following function takes `alpha` and `beta` and makes an object that represents a gamma distribution with those parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gamma_dist(alpha, beta):\n",
    "    \"\"\"Makes a gamma object.\"\"\"\n",
    "    dist = gamma(alpha, scale=1/beta)\n",
    "    dist.alpha = alpha\n",
    "    dist.beta = beta\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the prior distribution with `alpha=1.4` again and `beta=1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I claim without proof that we can do a Bayesian update with `k` goals just by making a gamma distribution with parameters `alpha+k` and `beta+1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_gamma(prior, data):\n",
    "    \"\"\"Update a gamma prior.\"\"\"\n",
    "    k, t = data\n",
    "    alpha = prior.alpha + k\n",
    "    beta = prior.beta + t\n",
    "    return make_gamma_dist(alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we update it with `k=4` goals in `t=1` game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After all the work we did with the grid, it might seem absurd that we can do a Bayesian update by adding two pairs of numbers.\n",
    "\n",
    "\n",
    "- So let's confirm that it works.\n",
    "\n",
    "\n",
    "- We'll make a `Pmf` with a discrete approximation of the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the result along with the posterior we computed using the grid algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decorate_rate(title=''):\n",
    "    decorate(xlabel='Goal scoring rate (lam)',\n",
    "             ylabel='PMF',\n",
    "             title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.plot(label='grid posterior', color='C1')\n",
    "posterior_conjugate.plot(label='conjugate posterior', \n",
    "                         color='C4', ls=':')\n",
    "\n",
    "decorate_rate('Posterior distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does `np.allclose()` Do?\n",
    "\n",
    "\n",
    "- It checks element-wise if the two arrays are nearly equal within a tolerance.\n",
    "\n",
    "\n",
    "- It returns True if all corresponding elements are close enough based on a default or specified tolerance.\n",
    "\n",
    "\n",
    "- It is useful for verifying numerical stability in Bayesian updates or probabilistic models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does that work?\n",
    "\n",
    "To understand how that works, we'll write the PDF of the gamma prior and the PMF of the Poisson likelihood, then multiply them together, because that's what the Bayesian update does.\n",
    "We'll see that the result is a gamma distribution, and we'll derive its parameters.\n",
    "\n",
    "Here's the PDF of the gamma prior, which is the probability density for each value of $\\lambda$, given parameters $\\alpha$ and $\\beta$:\n",
    "\n",
    "$$\\lambda^{\\alpha-1} e^{-\\lambda \\beta}$$\n",
    "\n",
    "We have omitted the normalizing factor; since we are planning to normalize the posterior distribution anyway, we don't really need it.\n",
    "\n",
    "Now suppose a team scores $k$ goals in $t$ games.\n",
    "The probability of this data is given by the PMF of the Poisson distribution, which is a function of $k$ with $\\lambda$ and $t$ as parameters.\n",
    "\n",
    "$$\\lambda^k e^{-\\lambda t}$$\n",
    "\n",
    "Again, we have omitted the normalizing factor, which makes it clearer that the gamma and Poisson distributions have the same functional form.\n",
    "When we multiply them together, we can pair up the factors and add up the exponents.\n",
    "The result is the unnormalized posterior distribution,\n",
    "\n",
    "$$\\lambda^{\\alpha-1+k} e^{-\\lambda(\\beta + t)}$$\n",
    "\n",
    "which we can recognize as an unnormalized gamma distribution with parameters $\\alpha + k$ and $\\beta + t$.\n",
    "\n",
    "This derivation provides insight into what the parameters of the posterior distribution mean: $\\alpha$ reflects the number of events that have occurred; $\\beta$ reflects the elapsed time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "\n",
    "- Unfortunately, there are only a few problems we can solve with conjugate priors.\n",
    "\n",
    "\n",
    "- For the vast majority of problems, there is no conjugate prior and no shortcut to compute the posterior distribution.\n",
    "\n",
    "\n",
    "- That's why we need grid algorithms and the methods we do not have enough time to get into in this course, Approximate Bayesian Computation (ABC) and Markov chain Monte Carlo methods (MCMC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1741855729933,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
