{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Interactive Variogram Calculation and Modeling Demonstration**\n",
    "\n",
    "## **Reidar B. Bratvold, Professor, University of Stavanger**  \n",
    "\n",
    "## **Overview**\n",
    "This interactive workflow demonstrates the calculation of **directional experimental variograms** in 2D. It is essential for quantifying spatial continuity in **sparsely sampled, irregular spatial data**.\n",
    "\n",
    "For a more comprehensive approach to variogram calculation, consider these resources:\n",
    "- [Experimental Variogram Calculation in Python with GeostatsPy](https://github.com/GeostatsGuy/PythonNumericalDemos/blob/master/GeostatsPy_variogram_calculation.ipynb)\n",
    "- [Determination of Major and Minor Spatial Continuity Directions in Python with GeostatsPy](https://github.com/GeostatsGuy/PythonNumericalDemos/blob/master/GeostatsPy_spatial_continuity_directions.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## **Spatial Continuity**\n",
    "**Spatial continuity** refers to the correlation of values over distance.\n",
    "\n",
    "- **No spatial continuity** â†’ No correlation between values, meaning data points are completely random.\n",
    "- **Perfect spatial continuity** â†’ Homogeneous phenomena where all values are highly correlated.\n",
    "\n",
    "To quantify spatial continuity, we use the **semivariogram**.\n",
    "\n",
    "---\n",
    "\n",
    "## **The Semivariogram**\n",
    "The **semivariogram** quantifies spatial variability as a function of separation distance:\n",
    "\n",
    "$$\n",
    "\\gamma(\\mathbf{h}) = \\frac{1}{2 N(\\mathbf{h})} \\sum^{N(\\mathbf{h})}_{\\alpha=1} (z(\\mathbf{u}_\\alpha) - z(\\mathbf{u}_\\alpha + \\mathbf{h}))^2  \n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( z(\\mathbf{u}_\\alpha) \\) and \\( z(\\mathbf{u}_\\alpha + \\mathbf{h}) \\) are sample values at the **tail** and **head** of the lag vector \\( \\mathbf{h} \\).\n",
    "- \\( N(\\mathbf{h}) \\) is the number of paired data points at that lag.\n",
    "\n",
    "The **semivariogram** is computed over multiple lag distances to obtain a **continuous function**.\n",
    "\n",
    "### **Relationship to Covariance and Correlogram**\n",
    "The semivariogram relates to the **covariance function** \\( C_x(\\mathbf{h}) \\) and **variance** \\( \\sigma^2_x \\):\n",
    "\n",
    "$$\n",
    "C_x(\\mathbf{h}) = \\sigma^2_x - \\gamma(\\mathbf{h})\n",
    "$$\n",
    "\n",
    "The **correlogram** measures correlation as:\n",
    "\n",
    "$$\n",
    "\\rho_x(\\mathbf{h}) = \\frac{C_x(\\mathbf{h})}{\\sigma^2_x}\n",
    "$$\n",
    "\n",
    "which satisfies:\n",
    "\n",
    "$$\n",
    "-1.0 \\leq \\rho_x(\\mathbf{h}) \\leq 1.0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **Variogram Observations**\n",
    "### **Observation #1: Variability Generally Increases with Distance**\n",
    "- As lag distance increases, spatial correlation typically decreases.\n",
    "- Some exceptions include **cyclic structures** (e.g., hole-effect models) where the variogram decreases over certain lag distances.\n",
    "\n",
    "### **Observation #2: Variograms Use All Possible Pairs Separated by \\( \\mathbf{h} \\)**\n",
    "- The semivariogram is computed from **all possible data pairs** within a given lag distance.\n",
    "- More pairs result in **more stable** variogram estimates.\n",
    "\n",
    "### **Observation #3: The Sill Represents the Degree of Correlation**\n",
    "- The **sill** is the total variance \\( \\sigma^2_x \\).\n",
    "- The covariance function follows:\n",
    "\n",
    "  $$\n",
    "  C_x(\\mathbf{h}) = \\sigma^2_x - \\gamma(\\mathbf{h})\n",
    "  $$\n",
    "\n",
    "- If the data variance is **standardized to 1.0**, then:\n",
    "\n",
    "  $$\n",
    "  \\rho_x(\\mathbf{h}) = \\sigma^2_x - \\gamma(\\mathbf{h})\n",
    "  $$\n",
    "\n",
    "### **Observation #4: The Range Defines the Limit of Correlation**\n",
    "- The **range** is the lag distance where the variogram reaches the sill.\n",
    "- Beyond the **range**, knowing a sample provides **no information** about another.\n",
    "\n",
    "### **Observation #5: The Nugget Effect (Discontinuity at \\( h = 0 \\))**\n",
    "- A sudden jump at **small lags** is called the **nugget effect**.\n",
    "- Causes include:\n",
    "  - **Measurement error**\n",
    "  - **Small-scale variability**\n",
    "  - **Mixed populations**\n",
    "\n",
    "The **relative nugget effect** is defined as:\n",
    "\n",
    "$$\n",
    "\\frac{\\text{nugget}}{\\text{sill}} \\times 100\\%\n",
    "$$\n",
    "\n",
    "Caution: A nugget effect can **mask spatial structure** if misinterpreted.\n",
    "\n",
    "---\n",
    "\n",
    "## **Variogram Calculation Parameters**\n",
    "### **Key Parameters**\n",
    "- **Azimuth (\\( \\theta \\))**: Direction of the lag vector.\n",
    "- **Azimuth tolerance**: Maximum deviation from the azimuth (set to 90Â° for isotropic variograms).\n",
    "- **Unit lag distance**: Bin size for lag distances (typically set to the minimum data spacing).\n",
    "- **Lag distance tolerance**: Acceptable variation in lag distance (commonly 50% of unit lag).\n",
    "- **Number of lags**: Typically **limited to half the dataset extent** to avoid unreliable estimates.\n",
    "- **Bandwidth**: Maximum allowable deviation from the lag vector.\n",
    "\n",
    "---\n",
    "\n",
    "## **Variogram Modeling**\n",
    "To model spatial continuity, we use **nested variogram structures**:\n",
    "\n",
    "$$\n",
    "\\Gamma_x(\\mathbf{h}) = \\sum_{i=1}^{n_{\\text{st}}} \\gamma_i(\\mathbf{h})\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( \\Gamma_x(\\mathbf{h}) \\) is the modeled variogram.\n",
    "- \\( n_{\\text{st}} \\) is the number of **nested** variogram structures.\n",
    "\n",
    "### **Common Variogram Models**\n",
    "1. **Spherical**\n",
    "2. **Exponential**\n",
    "3. **Gaussian**\n",
    "4. **Nugget**\n",
    "\n",
    "### **Less Common Models**\n",
    "- **Hole-effect**\n",
    "- **Damped hole-effect**\n",
    "- **Power-law** (for fractal-like data)\n",
    "\n",
    "Each variogram component follows a **geometric anisotropy model**:\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i = \\sqrt{\\left(\\frac{r_{\\text{maj}}}{a_{\\text{maj},i}}\\right)^2 + \\left(\\frac{r_{\\text{min}}}{a_{\\text{min},i}}\\right)^2}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( r_{\\text{maj}}, r_{\\text{min}} \\) are distances in the **major** and **minor** directions.\n",
    "- \\( a_{\\text{maj}}, a_{\\text{min}} \\) are the **ranges** in these directions.\n",
    "\n",
    "---\n",
    "\n",
    "## **Getting Started**\n",
    "Before running the workflow, ensure you have the required **sample dataset**:\n",
    "\n",
    "ðŸ“‚ **Data File:** `sample_data.csv`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import geostats    \n",
    "import os                                               # to set current working directory \n",
    "import sys                                              # supress output to screen for interactive variogram modeling\n",
    "import io\n",
    "import numpy as np                                      # arrays and matrix math\n",
    "import pandas as pd                                     # DataFrames\n",
    "import matplotlib.pyplot as plt                         # plotting\n",
    "from matplotlib.pyplot import cm                        # color maps\n",
    "from matplotlib import patches                          # draw variogram ellipse\n",
    "from ipywidgets import interactive                      # widgets and interactivity\n",
    "from ipywidgets import widgets                            \n",
    "from ipywidgets import Layout\n",
    "from ipywidgets import Label\n",
    "from ipywidgets import VBox, HBox\n",
    "import math\n",
    "from math import sin, cos, radians, pi\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to define three key function that will be used in the calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `vmodel_struct()`: Computes **variogram model values** (semivariance, covariance, correlation) for a given lag distance & azimuth.\n",
    "\n",
    "- `cova2_struct()`: Computes **covariance** for a given lag distance based on the selected **variogram model** (spherical, exponential, Gaussian, power-law).\n",
    "\n",
    "- `point_pos()`: Computes **spatial coordinates** of a point given an **initial position, distance, and azimuth**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. `vmodel_struct(nlag, xlag, azm, vario, istruct)`**\n",
    "\n",
    "### **Purpose**\n",
    "This function computes **variogram model values** (semivariance, covariance, and correlation) for a given **lag distance** and azimuthal direction.\n",
    "\n",
    "### **Inputs**\n",
    "- `nlag`: Number of lag distances to compute.\n",
    "- `xlag`: Lag distance increment.\n",
    "- `azm`: Azimuth direction (in degrees).\n",
    "- `vario`: Dictionary containing variogram model parameters.\n",
    "- `istruct`: Structure index (determines which variogram component to compute).\n",
    "\n",
    "### **Process**\n",
    "1. **Initialize Constants & Variables**:\n",
    "   - Define `MAXNST` (maximum structures) and `DEG2RAD` (degree-to-radian conversion).\n",
    "   - Initialize arrays for **index, lag distances, semivariance (Î³(h)), covariance, and correlation**.\n",
    "\n",
    "2. **Load Variogram Parameters**:\n",
    "    - Reads **nugget effect (`c0`) and nested structures (`cc`, `it`, `ang`, `aa`, `anis`)**.\n",
    "    - Supports **two nested variogram structures**.\n",
    "\n",
    "3. **Compute Spatial Offsets**:\n",
    "   - Converts **azimuth to x and y offsets**.\n",
    "\n",
    "4. **Compute Variogram Values**:\n",
    "   - Loops over all lag distances:\n",
    "     - Computes **covariance using `cova2_struct()`**.\n",
    "     - Computes **semivariance**:\n",
    "       $$ \\gamma(h) = \text{maxcov} - \text{cov}(h) $$\n",
    "     - Computes **correlation**:\n",
    "       $$ \n",
    "ho(h) = \f",
    "rac{\text{cov}(h)}{\text{maxcov}} $$\n",
    "     - Updates **spatial coordinates** (`xx, yy`).\n",
    "\n",
    "5. **Returns**:\n",
    "   - `index`: Lag indices.\n",
    "   - `h`: Lag distances.\n",
    "   - `gam`: Semivariance values.\n",
    "   - `cov`: Covariance values.\n",
    "   - `ro`: Correlation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def vmodel_struct(nlag: int, xlag: float, azm: float, vario: dict, istruct: int):\n",
    "    \"\"\"\n",
    "    Computes the variogram model values including semivariance, covariance, \n",
    "    and correlation for a given lag distance and azimuth.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    nlag : int\n",
    "        Number of lag distances to compute.\n",
    "    xlag : float\n",
    "        Lag distance increment.\n",
    "    azm : float\n",
    "        Azimuth direction in degrees.\n",
    "    vario : dict\n",
    "        Dictionary containing variogram model parameters.\n",
    "    istruct : int\n",
    "        Structure index for selecting the variogram component.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray)\n",
    "        - index: Lag indices.\n",
    "        - h: Lag distances.\n",
    "        - gam: Semivariance values.\n",
    "        - cov: Covariance values.\n",
    "        - ro: Correlation values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Constants\n",
    "    DEG2RAD = math.pi / 180.0  \n",
    "\n",
    "    # Initialize output arrays\n",
    "    index = np.zeros(nlag + 1)\n",
    "    h = np.zeros(nlag + 1)\n",
    "    gam = np.zeros(nlag + 1)\n",
    "    cov = np.zeros(nlag + 1)\n",
    "    ro = np.zeros(nlag + 1)\n",
    "\n",
    "    # Load variogram parameters from dictionary\n",
    "    nst = vario[\"nst\"]\n",
    "    c0 = vario[\"nug\"]\n",
    "\n",
    "    # Allocate structure arrays\n",
    "    cc = np.zeros(nst)\n",
    "    aa = np.zeros(nst)\n",
    "    it = np.zeros(nst)\n",
    "    ang = np.zeros(nst)\n",
    "    anis = np.zeros(nst)\n",
    "\n",
    "    # Assign primary structure\n",
    "    cc[0], it[0], ang[0], aa[0] = vario[\"cc1\"], vario[\"it1\"], vario[\"azi1\"], vario[\"hmaj1\"]\n",
    "    anis[0] = vario[\"hmin1\"] / vario[\"hmaj1\"]\n",
    "\n",
    "    # Assign secondary structure if present\n",
    "    if nst == 2:\n",
    "        cc[1], it[1], ang[1], aa[1] = vario[\"cc2\"], vario[\"it2\"], vario[\"azi2\"], vario[\"hmaj2\"]\n",
    "        anis[1] = vario[\"hmin2\"] / vario[\"hmaj2\"]\n",
    "\n",
    "    # Compute spatial offsets\n",
    "    xoff = math.sin(DEG2RAD * azm) * xlag\n",
    "    yoff = math.cos(DEG2RAD * azm) * xlag\n",
    "    #print(f\"x, y offsets = {xoff:.4f}, {yoff:.4f}\")\n",
    "\n",
    "    # Setup rotation matrix\n",
    "    rotmat, maxcov = geostats.setup_rotmat(c0, nst, it, cc, ang, 99999.9)\n",
    "\n",
    "    # Compute variogram model\n",
    "    xx, yy = 0.0, 0.0  \n",
    "    for il in range(nlag + 1):\n",
    "        index[il] = il\n",
    "        cov[il] = cova2_struct(0.0, 0.0, xx, yy, nst, c0, 9999.9, cc, aa, it, ang, anis, rotmat, maxcov, istruct)\n",
    "\n",
    "        # Compute semivariance\n",
    "        gam[il] = (c0 - cov[il]) if istruct == -1 else (cc[istruct] - cov[il])\n",
    "        \n",
    "        # Compute correlation\n",
    "        ro[il] = cov[il] / maxcov\n",
    "        h[il] = math.sqrt(max(xx**2 + yy**2, 0.0))\n",
    "\n",
    "        # Update spatial coordinates\n",
    "        xx += xoff\n",
    "        yy += yoff\n",
    "\n",
    "    #print(f\"Semivariance values: {gam}\")\n",
    "\n",
    "    return index, h, gam, cov, ro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. `cova2_struct(x1, y1, x2, y2, nst, c0, pmx, cc, aa, it, ang, anis, rotmat, maxcov, istruct)`**\n",
    "\n",
    "### **Purpose**\n",
    "Computes **covariance for a given lag distance** based on the **variogram model type** (spherical, exponential, Gaussian, power-law).\n",
    "\n",
    "### **Inputs**\n",
    "- `x1, y1, x2, y2`: Coordinates of two spatial points.\n",
    "- `nst`: Number of nested structures.\n",
    "- `c0`: Nugget effect.\n",
    "- `pmx`: Maximum covariance value.\n",
    "- `cc, aa, it, ang, anis`: Variogram structure parameters.\n",
    "- `rotmat`: Rotation matrix (for anisotropy).\n",
    "- `maxcov`: Maximum covariance.\n",
    "- `istruct`: Index of the variogram structure.\n",
    "\n",
    "### **Process**\n",
    "1. **Check for Small Distances**:\n",
    "   - If **distance is near zero**, returns **covariance equal to the sill**.\n",
    "\n",
    "2. **Compute Rotated Spatial Distances**:\n",
    "   - Applies **rotation matrix** to compute anisotropic distances.\n",
    "\n",
    "3. **Apply Variogram Model**:\n",
    "   - **Spherical Model**:\n",
    "     \n",
    "     $ C(h) = c_i \\left( 1 - hr \\times (1.5 - 0.5 hr^2) \\right), \\quad hr < 1 $\n",
    "     \n",
    "   - **Exponential Model**:\n",
    "     \n",
    "     $ C(h) = c_i \\exp\\left(-\f",
    "rac{3h}{a_i} \\right) $\n",
    "     \n",
    "   - **Gaussian Model**:\n",
    "     \n",
    "     $ C(h) = c_i \\exp\\left(-\f",
    "rac{3h^2}{a_i^2} \\right) $\n",
    "     \n",
    "   - **Power Model**:\n",
    "     \n",
    "     $ C(h) = pmx - c_i \\times h^{a_i} $\n",
    "\n",
    "4. **Returns**:\n",
    "   - Covariance value at given lag distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def cova2_struct(\n",
    "    x1: float, y1: float, x2: float, y2: float,\n",
    "    nst: int, c0: float, pmx: float, cc: np.ndarray, aa: np.ndarray,\n",
    "    it: np.ndarray, ang: np.ndarray, anis: np.ndarray,\n",
    "    rotmat: np.ndarray, maxcov: float, istruct: int\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Computes the covariance value for a given lag distance based on the specified variogram model.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    x1, y1, x2, y2 : float\n",
    "        Coordinates of two spatial points.\n",
    "    nst : int\n",
    "        Number of nested structures in the variogram model.\n",
    "    c0 : float\n",
    "        Nugget effect (discontinuity at the origin).\n",
    "    pmx : float\n",
    "        Maximum allowable covariance value.\n",
    "    cc, aa, it, ang, anis : np.ndarray\n",
    "        Arrays storing variogram model parameters:\n",
    "        - `cc`: Partial sill contribution.\n",
    "        - `aa`: Range parameters.\n",
    "        - `it`: Model type (1=Spherical, 2=Exponential, 3=Gaussian, 4=Power).\n",
    "        - `ang`: Variogram azimuth angles.\n",
    "        - `anis`: Anisotropy ratios (minor/major axis).\n",
    "    rotmat : np.ndarray\n",
    "        Rotation matrix for anisotropic transformations.\n",
    "    maxcov : float\n",
    "        Maximum covariance value.\n",
    "    istruct : int\n",
    "        Index of the variogram structure to compute.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Computed covariance value.\n",
    "    \"\"\"\n",
    "    \n",
    "    EPSILON = 1e-6  # Small threshold to avoid precision issues\n",
    "\n",
    "    # Compute distance components\n",
    "    dx, dy = x2 - x1, y2 - y1\n",
    "    h_sq = dx**2 + dy**2  \n",
    "\n",
    "    # If distance is near zero, return partial sill\n",
    "    if h_sq < EPSILON:\n",
    "        return cc[istruct]\n",
    "\n",
    "    # Initialize covariance value\n",
    "    cova2 = 0.0\n",
    "\n",
    "    # Transform coordinates using rotation matrix (for anisotropic effects)\n",
    "    dx1 = dx * rotmat[0, istruct] + dy * rotmat[1, istruct]\n",
    "    dy1 = (dx * rotmat[2, istruct] + dy * rotmat[3, istruct]) / anis[istruct]\n",
    "    h = math.sqrt(max(dx1**2 + dy1**2, 0.0))  # Ensure h is non-negative\n",
    "\n",
    "    # Return zero covariance if invalid structure index\n",
    "    if istruct == -1:\n",
    "        return 0.0\n",
    "\n",
    "    # Select and compute the appropriate variogram model\n",
    "    model_type = it[istruct]\n",
    "\n",
    "    if model_type == 1:  # Spherical Model\n",
    "        hr = h / aa[istruct]\n",
    "        if hr < 1.0:\n",
    "            cova2 += cc[istruct] * (1.0 - hr * (1.5 - 0.5 * hr**2))\n",
    "\n",
    "    elif model_type == 2:  # Exponential Model\n",
    "        cova2 += cc[istruct] * np.exp(-3.0 * h / aa[istruct])\n",
    "\n",
    "    elif model_type == 3:  # Gaussian Model\n",
    "        hh = -3.0 * (h**2) / (aa[istruct]**2)\n",
    "        cova2 += cc[istruct] * np.exp(hh)\n",
    "\n",
    "    elif model_type == 4:  # Power Model\n",
    "        cova2 += pmx - cc[istruct] * (h ** aa[istruct])\n",
    "\n",
    "    return cova2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. `point_pos(x0, y0, d, theta)`**\n",
    "\n",
    "### **Purpose**\n",
    "Computes **the spatial coordinates of a point** given an initial location `(x0, y0)`, a distance `d`, and an **angle `theta` (azimuth direction)**.\n",
    "\n",
    "### **Inputs**\n",
    "- `x0, y0`: Initial coordinates.\n",
    "- `d`: Distance to new point.\n",
    "- `theta`: Azimuth angle (in degrees).\n",
    "\n",
    "### **Process**\n",
    "1. Converts **azimuth from degrees to radians**.\n",
    "2. Computes **new x and y coordinates** using trigonometry:\n",
    "   \n",
    "   $ x = x_0 + d \\cos(\t\\theta_{{rad}}) $\n",
    "   \n",
    "   $ y = y_0 + d \\sin(\t\\theta_{{rad}}) $\n",
    "\n",
    "3. **Returns**:\n",
    "   - `(x, y)`: New point location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def point_pos(x0: float, y0: float, d: float, theta: float) -> tuple:\n",
    "    \"\"\"\n",
    "    Computes the new coordinates of a point given an initial position, \n",
    "    a distance, and an azimuth angle.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    x0, y0 : float\n",
    "        Initial coordinates.\n",
    "    d : float\n",
    "        Distance to the new point.\n",
    "    theta : float\n",
    "        Azimuth angle (in degrees, measured clockwise from north).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (float, float)\n",
    "        The new (x, y) coordinates after translation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert azimuth angle to radians (measured counterclockwise from x-axis)\n",
    "    theta_rad = math.radians(90 - theta)\n",
    "\n",
    "    # Compute new coordinates\n",
    "    x_new = x0 + d * math.cos(theta_rad)\n",
    "    y_new = y0 + d * math.sin(theta_rad)\n",
    "\n",
    "    return x_new, y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Tabular Data\n",
    "\n",
    "Here's the command to load our comma delimited data file in to a Pandas' DataFrame object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 3\n",
    "\n",
    "if data == 1:\n",
    "    df = pd.read_csv(\"sample_data_MV_biased.csv\")\n",
    "    df = df.rename(columns = {'Por':'Porosity'})            # rename feature(s)\n",
    "    df['Porosity'] = df['Porosity']*100.0\n",
    "    df = df.iloc[:,1:]                                      # remove first column\n",
    "elif data == 2:\n",
    "    df = pd.read_csv(\"spatial_nonlinear_MV_facies_v3.csv\")\n",
    "    df = df.rename(columns = {'Por':'Porosity'})            # rename feature(s)\n",
    "    df = df.iloc[:,1:] \n",
    "elif data == 3:\n",
    "    df = pd.read_csv(\"12_sample_data.csv\")\n",
    "    df = df.rename(columns = {'Por':'Porosity'})            # rename feature(s) \n",
    "    df['Porosity'] = df['Porosity']*100.0\n",
    "    df = df.iloc[:,1:] \n",
    "elif data == 4:\n",
    "    df = pd.read_csv(\"spatial_nonlinear_MV_facies_v5_sand_only.csv\")\n",
    "    df = df.rename(columns = {'Por':'Porosity'})            # rename feature(s) \n",
    "    df = df.iloc[:,1:] \n",
    "else:\n",
    "    df = pd.read_csv(\"spatial_nonlinear_MV_facies_v1.csv\")\n",
    "    df = df.rename(columns = {'Por':'Porosity'})            # rename feature(s)\n",
    "    df = df.iloc[:,1:] \n",
    "    \n",
    "df.head()                                               # we could also use this command for a table preview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features:\n",
    "\n",
    "* **X** - x coordinate in meters\n",
    "* **Y** - y coordinate in meters\n",
    "* **Porosity** - rock porosity averaged over a specific rock unit from a vertical well\n",
    "* **Perm** - rock permeability averaged (scaled up) over a specific rock unit from a vertical well \n",
    "* **AI** - acoustic impedance from a seismic cube assigned at a specific rock unit and at the location of a vertical well \n",
    "* **facies** - facies, 0 - shale, 1 - sandstone\n",
    "\n",
    "Concerning facies:\n",
    "\n",
    "We will work with all facies pooled together. I wanted to simplify this workflow and focus more on spatial continuity direction detection. Finally, by not using facies we do have more samples to support our statistical inference. Most often facies are essential in the subsurface model. Don't worry we will check if this is reasonable in a bit.   \n",
    "\n",
    "You are welcome to repeat this workflow on a by-facies basis.  The following code could be used to build DataFrames ('df_sand' and 'df_shale') for each facies.\n",
    "\n",
    "```p\n",
    "df_sand = pd.DataFrame.copy(df[df['Facies'] == 1]).reset_index()  # copy only 'Facies' = sand records\n",
    "df_shale = pd.DataFrame.copy(df[df['Facies'] == 0]).reset_index() # copy only 'Facies' = shale records\n",
    "```\n",
    "\n",
    "Let's look at summary statistics for all facies combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()                               # summary table of sand only DataFrame statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the Model Parameters\n",
    "\n",
    "See the the following model parameters:\n",
    "\n",
    "* **xmin**, **xmax**, **ymin** and **ymax** - extents of the dataset for plotting\n",
    "* **feature** and **feature_units** - feature of interest and associated units\n",
    "* **vmin** and **vmax** - minimum and maximum of the feature of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = 0.0; xmax = 1000.0                                # spatial extents in x and y\n",
    "ymin = 0.0; ymax = 1000.0\n",
    "feature = 'Porosity'; feature_units = 'percentage'         # name and units of the feature of interest\n",
    "vmin = 0.0; vmax = 25.0                                  # min and max of the feature of interest\n",
    "cmap = plt.cm.inferno                                    # set the color map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform the feature to standard normal (mean = 0.0, standard deviation = 1.0, Gaussian shape). This is required for sequential Gaussian simulation (common target for our variogram models) and the Gaussian transform assists with outliers and provides more interpretable variograms. \n",
    "\n",
    "Let's look at the inputs for the GeostatsPy nscore program.  Note the output include an ndarray with the transformed values (in the same order as the input data in Dataframe 'df' and column 'vcol'), and the transformation table in original values and also in normal score values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command will transform the Porosity and Permeabilty to standard normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform to Gaussian by Facies\n",
    "df['N' + feature], tvPor, tnsPor = geostats.nscore(df, feature) # nscore transform for all facies porosity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the updated DataFrame to make sure that we now have the normal score porosity and permeability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()                                               # preview sand DataFrame with nscore transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks good! One way to check is to see if the relative magnitudes of the normal score transformed values match the original values.  e.g. that the normal score transform of 0.10 porosity normal score is less than the normal score transform of 0.14 porsity.  Also, the normal score transform of values close to the mean value should be close to 0.0 \n",
    "\n",
    "Let's also check the original and transformed sand and shale porosity distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)                                        # plot original sand and shale porosity histograms\n",
    "plt.hist(df[feature], facecolor='red',bins=np.linspace(vmin,vmax,1000),histtype=\"stepfilled\",alpha=0.2,density=True,cumulative=True,edgecolor='black')\n",
    "plt.xlim([vmin,vmax]); plt.ylim([0,1.0])\n",
    "plt.xlabel(feature + '(' + feature_units + ')'); plt.ylabel('Frequency'); plt.title('Porosity')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)  \n",
    "plt.hist(df['N'+feature], facecolor='blue',bins=np.linspace(-3.0,3.0,1000),histtype=\"stepfilled\",alpha=0.2,density=True,cumulative=True,edgecolor='black')\n",
    "plt.xlim([-3.0,3.0]); plt.ylim([0,1.0])\n",
    "plt.xlabel('Gaussian Transformed ' + feature); plt.ylabel('Frequency'); plt.title('Guassian Transformed ' + feature)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the normal score transform has correctly transformed the feature to standard normal.\n",
    "\n",
    "#### Inspection of Posted Data\n",
    "\n",
    "Data visualization is very useful to detect patterns. Our brains are very good at pattern detection. I promote quantitative methods and recognize issues with cognitive bias, but it is important to recognize the value is expert intepretation based on data visualization.\n",
    "\n",
    "* This data visualization will also be important to assist with parameter selection for the variogram calculation search template.\n",
    "\n",
    "Let's plot the location maps of the original feature and the normal score transforms of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def locmap_st(df, x_col, y_col, feature_col, xmin, xmax, ymin, ymax, \n",
    "              vmin, vmax, title, xlabel, ylabel, cmap=\"inferno\"):\n",
    "    \"\"\"\n",
    "    Plots a spatial location map of a feature using a scatter plot in the current subplot.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe containing spatial data.\n",
    "    x_col, y_col : str\n",
    "        Column names for X and Y coordinates.\n",
    "    feature_col : str\n",
    "        Column name for the feature to be visualized.\n",
    "    xmin, xmax : float\n",
    "        Minimum and maximum values for the X-axis.\n",
    "    ymin, ymax : float\n",
    "        Minimum and maximum values for the Y-axis.\n",
    "    vmin, vmax : float\n",
    "        Minimum and maximum values for the color scale.\n",
    "    title : str\n",
    "        Title of the plot.\n",
    "    xlabel, ylabel : str\n",
    "        Labels for the X and Y axes.\n",
    "    cmap : str (default=\"inferno\")\n",
    "        Colormap for visualization.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None (displays the plot)\n",
    "    \"\"\"\n",
    "\n",
    "    ax = plt.gca()  # Get the current subplot\n",
    "    scatter = ax.scatter(\n",
    "        df[x_col], df[y_col], c=df[feature_col],\n",
    "        cmap=cmap, edgecolors=\"black\", vmin=vmin, vmax=vmax\n",
    "    )\n",
    "\n",
    "    # Add color bar\n",
    "    cbar = plt.colorbar(scatter, ax=ax, shrink=0.8)\n",
    "    cbar.set_label(feature_col)\n",
    "\n",
    "    # Set axis labels and limits\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))  # Ensure good layout\n",
    "\n",
    "plt.subplot(121)  # First subplot (Porosity)\n",
    "locmap_st(df, 'X', 'Y', feature, 0, 1000, 0, 1000, vmin, vmax, 'Porosity', 'X (m)', 'Y (m)', cmap=\"inferno\")\n",
    "\n",
    "plt.subplot(122)  # Second subplot (Gaussian Transformed Porosity)\n",
    "locmap_st(df, 'X', 'Y', 'N' + feature, 0, 1000, 0, 1000, -3, 3, 'Gaussian Transformed ' + feature, 'X (m)', 'Y (m)', cmap=\"inferno\")\n",
    "\n",
    "plt.subplots_adjust(left=0.05, bottom=0.1, right=0.95, top=0.9, wspace=0.3, hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see?  Here's my observations:\n",
    "\n",
    "* there is a high degree of spatial agreement between porosity and permeability, this is supported by the high correlation evident in the cross plot.\n",
    "* there are no discontinuities that could suggest that facies represent a distinct change, rather the porosity and permeability seem continuous and the assigned facies are a truncation of their continous behavoir, we doing 'ok' with no facies\n",
    "* suspect a 045 azimuth major direction of continuity (up - right)\n",
    "* there may be cycles in the 135 azimuth \n",
    "* there will not likely be a nugget effect, but there is an hint of some short scale discontinuity?\n",
    "\n",
    "**Do you agree?** If you have a different observations, drop me a line at mpyrcz@austin.utexas.edu and I'll add to this lesson with credit!\n",
    "\n",
    "#### Experimental Variograms\n",
    "\n",
    "We can use the location maps to help determine good variogram calculation parameters. For example:\n",
    "\n",
    "```p\n",
    "tmin = -9999.; tmax = 9999.; \n",
    "lag_dist = 100.0; lag_tol = 50.0; nlag = 7; bandh = 9999.9; azi = azi; atol = 22.5; isill = 1\n",
    "```\n",
    "* **tmin**, **tmax** are trimming limits - set to have no impact, no need to filter the data\n",
    "* **lag_dist**, **lag_tol** are the lag distance, lag tolerance - set based on the common data spacing (100m) and tolerance as 100% of lag distance for additonal smoothing\n",
    "* **nlag** is number of lags - set to extend just past 50 of the data extent\n",
    "* **bandh** is the horizontal band width - set to have no effect\n",
    "* **azi** is the azimuth -  it has not effect since we set atol, the azimuth tolerance, to 90.0\n",
    "* **isill** is a boolean to standardize the distribution to a variance of 1 - it has no effect since the previous nscore transform sets the variance to 1.0\n",
    "\n",
    "#### Dashboard for Interactive Variogram Calculation and Modeling\n",
    "\n",
    "Below we make a dashboard with the ipywidgets and matplotlib Python packages for calculating and modeling experimental variograms.\n",
    "\n",
    "* allowing you to calculate and model the variogram of the normal score transformed variogram interactively while changing (and exploring) the search template parameters.\n",
    "\n",
    "* first calculate the isotropic or directional variogram(s)\n",
    "\n",
    "* then fit the same isotropic or directional variogram(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need a variogram calculation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_variogram(nug, nst, it1, c1, ang1, hmaj1, hmin1, it2=None, c2=None, ang2=None, hmaj2=None, hmin2=None):\n",
    "    \"\"\"\n",
    "    Creates a variogram model structure for use in variogram simulations.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    nug : float\n",
    "        Nugget effect.\n",
    "    nst : int\n",
    "        Number of nested structures (1 or 2).\n",
    "    it1 : int\n",
    "        Variogram type for first structure (1=Spherical, 2=Exponential, 3=Gaussian, 4=Power).\n",
    "    c1 : float\n",
    "        Sill contribution of first structure.\n",
    "    ang1 : float\n",
    "        Major azimuth angle for first structure.\n",
    "    hmaj1 : float\n",
    "        Major range for first structure.\n",
    "    hmin1 : float\n",
    "        Minor range for first structure.\n",
    "    it2 : int, optional\n",
    "        Variogram type for second structure (if applicable).\n",
    "    c2 : float, optional\n",
    "        Sill contribution of second structure.\n",
    "    ang2 : float, optional\n",
    "        Major azimuth angle for second structure.\n",
    "    hmaj2 : float, optional\n",
    "        Major range for second structure.\n",
    "    hmin2 : float, optional\n",
    "        Minor range for second structure.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Variogram model dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    vario = {\n",
    "        \"nug\": nug,\n",
    "        \"nst\": nst,\n",
    "        \"it1\": it1,\n",
    "        \"cc1\": c1,\n",
    "        \"azi1\": ang1,\n",
    "        \"hmaj1\": hmaj1,\n",
    "        \"hmin1\": hmin1,\n",
    "    }\n",
    "\n",
    "    if nst == 2:\n",
    "        vario.update({\n",
    "            \"it2\": it2,\n",
    "            \"cc2\": c2,\n",
    "            \"azi2\": ang2,\n",
    "            \"hmaj2\": hmaj2,\n",
    "            \"hmin2\": hmin2,\n",
    "        })\n",
    "\n",
    "    return vario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive calculation of the experimental variogram\n",
    "l = widgets.Text(value='                              Variogram Calculation Interactive Demonstration, Michael Pyrcz, Associate Professor, The University of Texas at Austin',layout=Layout(width='950px', height='30px'))\n",
    "lag = widgets.FloatSlider(min = 10, max = 500, value = 10, step = 10, description = 'lag',orientation='vertical',layout=Layout(width='90px', height='200px'))\n",
    "lag.style.handle_color = 'gray'\n",
    "\n",
    "lag_tol = widgets.FloatSlider(min = 5, max = 500, value = 5, step = 10, description = 'lag tolerance',orientation='vertical',layout=Layout(width='90px', height='200px'))\n",
    "lag_tol.style.handle_color = 'gray'\n",
    "\n",
    "nlag = widgets.IntSlider(min = 1, max = 100, value = 100, step = 1, description = 'number of lags',orientation='vertical',layout=Layout(width='90px', height='200px'))\n",
    "nlag.style.handle_color = 'gray'\n",
    "\n",
    "azi = widgets.FloatSlider(min = 0, max = 360, value = 0, step = 5, description = 'azimuth',orientation='vertical',layout=Layout(width='90px', height='200px'))\n",
    "azi.style.handle_color = 'gray'\n",
    "\n",
    "azi_tol = widgets.FloatSlider(min = 10, max = 90, value = 10, step = 5, description = 'azimuth tolerance',orientation='vertical',layout=Layout(width='120px', height='200px'))\n",
    "azi_tol.style.handle_color = 'gray'\n",
    "\n",
    "bandwidth = widgets.FloatSlider(min = 100, max = 2000, value = 2000, step = 100, description = 'bandwidth',orientation='vertical',layout=Layout(width='90px', height='200px'))\n",
    "azi_tol.style.handle_color = 'gray'\n",
    "\n",
    "\n",
    "ui1 = widgets.HBox([lag,lag_tol,nlag,azi,azi_tol,bandwidth],) # basic widget formatting    \n",
    "ui = widgets.VBox([l,ui1],)\n",
    "\n",
    "def f_make(lag,lag_tol,nlag,azi,azi_tol,bandwidth):     # function to take parameters, calculate variogram and plot\n",
    "#    text_trap = io.StringIO()\n",
    "#    sys.stdout = text_trap\n",
    "    global lags,gammas,npps,lags2,gammas2,npps2\n",
    "    tmin = -9999.9; tmax = 9999.9\n",
    "    lags, gammas, npps = geostats.gamv(df,\"X\",\"Y\",\"N\"+feature,tmin,tmax,lag,lag_tol,nlag,azi,azi_tol,bandwidth,isill=1.0)\n",
    "    lags2, gammas2, npps2 = geostats.gamv(df,\"X\",\"Y\",\"N\"+feature,tmin,tmax,lag,lag_tol,nlag,azi+90.0,azi_tol,bandwidth,isill=1.0)\n",
    "    \n",
    "    plt.subplot(111)                                    # plot experimental variogram\n",
    "    plt.scatter(lags,gammas,color = 'black',s = npps*0.03,label = 'Major Azimuth ' +str(azi), alpha = 0.8)\n",
    "    plt.scatter(lags2,gammas2,color = 'red',s = npps*0.03,label = 'Minor Azimuth ' +str(azi+90.0), alpha = 0.8)\n",
    "    plt.plot([0,2000],[1.0,1.0],color = 'black')\n",
    "    plt.xlabel(r'Lag Distance $\\bf(h)$, (m)')\n",
    "    plt.ylabel(r'$\\gamma \\bf(h)$')\n",
    "    if azi_tol < 90.0:\n",
    "        plt.title('Directional NSCORE ' + feature + ' Variogram - Azi. ' + str(np.round(azi,0)) + ', Azi. Tol.' + str(azi_tol))\n",
    "    else: \n",
    "        plt.title('Omni Directional NSCORE ' + feature + ' Variogram ')\n",
    "    plt.xlim([0,1000]); plt.ylim([0,1.8])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplots_adjust(left=0.0, bottom=0.0, right=1.5, top=1.0, wspace=0.3, hspace=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "    \n",
    "# connect the function to make the samples and plot to the widgets    \n",
    "interactive_plot = widgets.interactive_output(f_make, {'lag':lag,'lag_tol':lag_tol,'nlag':nlag,'azi':azi,'azi_tol':azi_tol,'bandwidth':bandwidth})\n",
    "interactive_plot.clear_output(wait = True)               # reduce flickering by delaying plot updating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Variogram Calculation Demonstration\n",
    "\n",
    "* calculate omnidirectional and direction experimental variograms \n",
    "\n",
    "Calculate interpretable experimental variograms for sparse, irregularly-space spatial data. Note, size of the experimental point is scaled by the number of pairs.\n",
    "\n",
    "* **azimuth** is the azimuth of the lag vector\n",
    "\n",
    "* **azimuth tolerance** is the maximum allowable departure from the azimuth\n",
    "\n",
    "* **unit lag distance** the size of the bins in lag distance\n",
    "\n",
    "* **lag distance tolerance** - the allowable tolerance in lage distance\n",
    "\n",
    "* **number of lags** - number of lags in the experimental variogram\n",
    "\n",
    "* **bandwidth** - maximum departure from the lag vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ui, interactive_plot) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Nested Variogram Modeling Demostration - Nested Structures and Azimuth Interpolation\n",
    "\n",
    "* select the nested structures and their types, contributions and major and minor ranges, visualize structures and azimuth interpolated variogram \n",
    "\n",
    "### The Problem\n",
    "\n",
    "Fit a positive definite variogram model based on the addition of multiple structures each describing spatial components of the feature variance \n",
    "\n",
    "* **nug**: nugget effect\n",
    "\n",
    "* **c1 / c2**: contributions of the sill - note, **c1** is set at 1.0 - **nug** - **c2**\n",
    "\n",
    "* **hmaj1 / hmaj2**: range in the major direction\n",
    "\n",
    "* **hmin1 / hmin2**: range in the minor direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive calculation of the sample set (control of source parametric distribution and number of samples)\n",
    "l = widgets.Text(value='Variogram Modeling, Visualize Nested Structures and Azimuth Interpolation',layout=Layout(width='950px', height='30px'))\n",
    "#nug = widgets.FloatSlider(min = 0.0001, max = 1.0, value = 0.0001, step = 0.1, description = r'$c_{nugget}$',orientation='vertical',layout=Layout(width='60px', height='200px'))\n",
    "\n",
    "#Nugget\n",
    "nug = widgets.FloatSlider(\n",
    "    min=0.0001, \n",
    "    max=1.0, \n",
    "    value=0.0001, \n",
    "    step=0.1, \n",
    "    description=r'$c_{nugget}$',\n",
    "    orientation='vertical',\n",
    "    layout=Layout(width='60px', height='220px')  # a bit taller so the text fits\n",
    ")\n",
    "nug.style = {'handle_color': 'gray', 'description_position': 'top'}\n",
    "\n",
    "#nug.style.handle_color = 'gray'\n",
    "it1 = widgets.Dropdown(options=['Spherical', 'Exponential', 'Gaussian'],value='Spherical',\n",
    "    description=r'$Type_1$:',disabled=False,layout=Layout(width='200px', height='30px'))\n",
    "# c1 = widgets.FloatSlider(min=0.0001, max = 1.0, value = 0.2, description = r'$c_1$',orientation='vertical',layout=Layout(width='60px', height='200px'))\n",
    "# c1.style.handle_color = 'gray'\n",
    "\n",
    "#hmaj1 = widgets.FloatSlider(min=0.01, max = 10000.0, value = 800.0, step = 25.0, description = r'$a_{1,maj}$',orientation='vertical',layout=Layout(width='60px', height='200px'))\n",
    "#hmaj1.style.handle_color = 'black'\n",
    "\n",
    "#hmaj1\n",
    "hmaj1 = widgets.FloatSlider(\n",
    "    min=0.01, max=10000, value=800, step=25,\n",
    "    description=r'$c_{hmaj1}$',\n",
    "    orientation='vertical',\n",
    "    layout=Layout(width='60px', height='220px')\n",
    ")\n",
    "hmaj1.style = {'handle_color': 'gray', 'description_position': 'top'}\n",
    "\n",
    "\n",
    "#hmin1 = widgets.FloatSlider(min = 0.01, max = 10000.0, value = 325.0, step = 25.0, description = r'$a_{1,min}$',orientation='vertical',layout=Layout(width='60px', height='200px'))\n",
    "#hmin1.style.handle_color = 'red'\n",
    "\n",
    "#hmin1\n",
    "hmin1 = widgets.FloatSlider(\n",
    "    min=0.01, \n",
    "    max=10000.0, \n",
    "    value=325, \n",
    "    step=25, \n",
    "    description=r'$c_{hmin1}$',\n",
    "    orientation='vertical',\n",
    "    layout=Layout(width='60px', height='220px')  # a bit taller so the text fits\n",
    ")\n",
    "hmin1.style = {'handle_color': 'gray', 'description_position': 'top'}\n",
    "\n",
    "it2 = widgets.Dropdown(options=['Spherical', 'Exponential', 'Gaussian'],value='Spherical',\n",
    "    description=r'$Type_2$:',disabled=False,layout=Layout(width='200px', height='30px'))\n",
    "\n",
    "\n",
    "#c2 = widgets.FloatSlider(min=0.0001, max = 1.0, value = 0.0001, description = r'$c_2$',orientation='vertical',layout=Layout(width='60px', height='200px'))\n",
    "#c2.style.handle_color = 'gray'\n",
    "#c2\n",
    "c2 = widgets.FloatSlider(\n",
    "    min=0.0001, \n",
    "    max=1.0, \n",
    "    value=0.0001, \n",
    "    step=0.1, \n",
    "    description=r'$c_{c2}$',\n",
    "    orientation='vertical',\n",
    "    layout=Layout(width='60px', height='220px')  # a bit taller so the text fits\n",
    ")\n",
    "c2.style = {'handle_color': 'gray', 'description_position': 'top'}\n",
    "\n",
    "#hmaj2 = widgets.FloatSlider(min=0.01, max = 10000.0, value = 800.0, step = 25.0, description = r'$a_{2,maj}$',orientation='vertical',layout=Layout(width='60px', height='200px'))\n",
    "#hmaj2.style.handle_color = 'black'\n",
    "#hmaj2\n",
    "hmaj2 = widgets.FloatSlider(\n",
    "    min=0.01, \n",
    "    max=10000.0, \n",
    "    value=800, \n",
    "    step=25, \n",
    "    description=r'$c_{hmaj2}$',\n",
    "    orientation='vertical',\n",
    "    layout=Layout(width='60px', height='220px')  # a bit taller so the text fits\n",
    ")\n",
    "hmaj2.style = {'handle_color': 'gray', 'description_position': 'top'}\n",
    "\n",
    "#hmin2 = widgets.FloatSlider(min = 0.01, max = 10000.0, value = 325.0, step = 25.0, description = r'$a_{2,min}$',orientation='vertical',layout=Layout(width='60px', height='200px'))\n",
    "#hmin2.style.handle_color = 'red'\n",
    "#hmin2\n",
    "hmin2 = widgets.FloatSlider(\n",
    "    min=0.01, \n",
    "    max=10000.0, \n",
    "    value=325, \n",
    "    step=25, \n",
    "    description=r'$c_{hmin2}$',\n",
    "    orientation='vertical',\n",
    "    layout=Layout(width='60px', height='220px')  # a bit taller so the text fits\n",
    ")\n",
    "hmin2.style = {'handle_color': 'gray', 'description_position': 'top'}\n",
    "\n",
    "#new_azimuth = widgets.FloatSlider(min = 0.0, max = 360.0, value = 45.0, step = 5.0, description = r'$azi_{inter}$',orientation='vertical',layout=Layout(width='60px', height='200px'))\n",
    "#new_azimuth.style.handle_color = 'purple'\n",
    "#new_azimuth\n",
    "new_azimuth = widgets.FloatSlider(\n",
    "    min=0.0, \n",
    "    max=360, \n",
    "    value=45, \n",
    "    step=5, \n",
    "    description=r'$c_{new_azimuth}$',\n",
    "    orientation='vertical',\n",
    "    layout=Layout(width='60px', height='220px')  # a bit taller so the text fits\n",
    ")\n",
    "new_azimuth.style = {'handle_color': 'gray', 'description_position': 'top'}\n",
    "\n",
    "ui9 = widgets.HBox([nug,it1,hmaj1,hmin1,it2,c2,hmaj2,hmin2,new_azimuth],)                   # basic widget formatting   \n",
    "#ui2 = widgets.HBox([it2,c2,hmaj2,hmin2],)                   # basic widget formatting   \n",
    "ui10 = widgets.VBox([l,ui9],)\n",
    "\n",
    "def convert_type(it):\n",
    "    if it == 'Spherical': \n",
    "        return 1\n",
    "    elif it == 'Exponential':\n",
    "        return 2\n",
    "    else: \n",
    "        return 3\n",
    "\n",
    "def f_make2(nug,it1,hmaj1,hmin1,it2,c2,hmaj2,hmin2,new_azimuth):                       # function to take parameters, make sample and plot\n",
    "    azimuth = azi.value\n",
    "    c1 = 1.0 - nug - c2\n",
    "    it1 = convert_type(it1); it2 = convert_type(it2)\n",
    "    if c2 > 0.0:\n",
    "        nst = 2\n",
    "    else:\n",
    "        nst = 1\n",
    "    \n",
    "    vario = make_variogram(nug,nst,it1,c1,0.0,hmaj1,hmin1,it2,c2,0.0,hmaj2,hmin2) # make model object\n",
    "    nlag = 100; xlag = 10;                                     \n",
    "    index_maj,h_maj,gam_maj,cov_maj,ro_maj = geostats.vmodel(nlag,xlag,0.0,vario)   # project the model in the major azimuth                                                  # project the model in the 135 azimuth\n",
    "    index_min,h_min,gam_min,cov_min,ro_min = geostats.vmodel(nlag,xlag,90.0,vario)\n",
    "    index_new,h_new,gam_new,cov_new,ro_new = geostats.vmodel(nlag,xlag,azimuth-new_azimuth,vario)\n",
    "    \n",
    "    _,h_maj0,gam_maj0,_,_ = vmodel_struct(nlag,xlag,0.0,vario,-1) \n",
    "    _,h_maj1,gam_maj1,_,_ = vmodel_struct(nlag,xlag,0.0,vario,0) \n",
    "    _,h_maj2,gam_maj2,_,_ = vmodel_struct(nlag,xlag,0.0,vario,1) \n",
    "    _,h_min0,gam_min0,_,_ = vmodel_struct(nlag,xlag,90.0,vario,-1) \n",
    "    _,h_min1,gam_min1,_,_ = vmodel_struct(nlag,xlag,90.0,vario,0) \n",
    "    _,h_min2,gam_min2,_,_ = vmodel_struct(nlag,xlag,90.0,vario,1) \n",
    "    _,h_new0,gam_new0,_,_ = vmodel_struct(nlag,xlag,azimuth-new_azimuth,vario,-1) \n",
    "    _,h_new1,gam_new1,_,_ = vmodel_struct(nlag,xlag,azimuth-new_azimuth,vario,0) \n",
    "    _,h_new2,gam_new2,_,_ = vmodel_struct(nlag,xlag,azimuth-new_azimuth,vario,1) \n",
    "    \n",
    "    plt.subplot(221)                                    # plot experimental variogram\n",
    "    plt.scatter(lags,gammas,color = 'black',s = npps*0.03,label = 'Major Azimuth ' +str(azimuth), alpha = 0.8,zorder=10)\n",
    "    plt.plot(h_maj,gam_maj,color = 'black',lw=3,zorder=10)\n",
    "    if nug > 0.0001: \n",
    "        plt.plot(h_maj0,gam_maj0,color = 'black',lw=1.5)\n",
    "        plt.fill_between(h_maj,gam_maj0,np.full(len(h_maj),0),color='grey',alpha=1.0,zorder=1,label = 'Nugget')\n",
    "    if c1 > 0.0001: \n",
    "        plt.plot(h_maj,gam_maj1+gam_maj0,color = 'black',lw=1.5)\n",
    "        plt.fill_between(h_maj,gam_maj1+gam_maj0,gam_maj0,color='darkorange',alpha=1.0,zorder=1,label = 'Structure #1')\n",
    "    \n",
    "    if c2 > 0.0001:   \n",
    "        plt.plot(h_maj,gam_maj2+gam_maj1+gam_maj0,color = 'black',lw=1.5)\n",
    "        plt.fill_between(h_maj,gam_maj2+gam_maj1+gam_maj0,gam_maj1+gam_maj0,color='deepskyblue',alpha=1.0,zorder=1,label='Structure #2')\n",
    "    \n",
    "    plt.plot([0,2000],[1.0,1.0],color = 'black',ls='--')\n",
    "    plt.xlabel(r'Lag Distance $\\bf(h)$, (m)'); plt.ylabel(r'$\\gamma \\bf(h)$')\n",
    "    if azi_tol.value < 90.0:\n",
    "        plt.title('Major Directional NSCORE ' + feature + ' Variogram - Azi. ' + str(azimuth))\n",
    "    else: \n",
    "        plt.title('Omni Directional NSCORE ' + feature + ' Variogram ')\n",
    "\n",
    "    if c1 > 0.0001:\n",
    "        plt.vlines(hmaj1,0,1.8,color='black',lw=1.5); \n",
    "        plt.annotate('Structure 1 Range',[hmaj1-30,1.3],rotation=90.0);\n",
    "    if c2 > 0.0001:\n",
    "        plt.vlines(hmaj2,0,1.8,color='black',lw=2.0)\n",
    "        plt.annotate('Structure 2 Range',[hmaj2-30,1.3],color='black',rotation=90.0)\n",
    "    plt.xlim([0,1000]); plt.ylim([0,1.8])\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(222)                                    # plot experimental variogram\n",
    "    plt.scatter(lags2,gammas2,color = 'red',s = npps*0.03,label = 'Minor Azimuth ' +str(azimuth+90.0), alpha = 0.8,zorder=10)\n",
    "    plt.plot(h_min,gam_min,color = 'red',lw=3)\n",
    "    if nug > 0.0001:\n",
    "        plt.plot(h_min0,gam_min0,color = 'red',lw=1.5)\n",
    "        plt.fill_between(h_min,gam_min0,np.full(len(h_maj),0),color='grey',alpha=1.0,zorder=1,label = 'Nugget')\n",
    "    if c1 > 0.0001:  \n",
    "        plt.plot(h_min,gam_min1+gam_min0,color = 'red',lw=1.5)\n",
    "        plt.fill_between(h_min,gam_min1+gam_min0,gam_min0,color='darkorange',alpha=1.0,zorder=1,label = 'Structure #1')\n",
    "    \n",
    "    if c2 > 0.0001:   \n",
    "        plt.plot(h_min,gam_min2+gam_min1+gam_min0,color = 'red',lw=1.5)\n",
    "        plt.fill_between(h_min,gam_min2+gam_min1+gam_min0,gam_min1+gam_min0,color='deepskyblue',alpha=1.0,zorder=1,label='Structure #2')\n",
    "    \n",
    "    plt.plot([0,2000],[1.0,1.0],color = 'black',ls='--')\n",
    "    plt.xlabel(r'Lag Distance $\\bf(h)$, (m)')\n",
    "    plt.ylabel(r'$\\gamma \\bf(h)$')\n",
    "    if azi_tol.value < 90.0:\n",
    "        plt.title('Minor Directional NSCORE ' + feature + ' Variogram - Azi. ' + str(azimuth + 90.0))\n",
    "    else: \n",
    "        plt.title('Omni Directional NSCORE ' + feature + ' Variogram ')\n",
    "    if c1 > 0.0001:      \n",
    "        plt.vlines(hmin1,0,1.8,color='red',lw=1.5)\n",
    "        plt.annotate('Structure 1 Range',[hmin1-30,1.3],color='red',rotation=90.0)\n",
    "    if c2 > 0.0001:  \n",
    "        plt.vlines(hmin2,0,1.8,color='red',lw=2.0)\n",
    "        plt.annotate('Structure 2 Range',[hmin2-30,1.3],color='red',rotation=90.0)\n",
    "    plt.xlim([0,1000]); plt.ylim([0,1.8])\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(223)                                    # plot experimental variogram\n",
    "    plt.plot(h_new,gam_new,color = 'purple',lw=3)\n",
    "    if nug > 0.0001:\n",
    "        plt.plot(h_new0,gam_new0,color = 'purple',lw=1.5)\n",
    "        plt.fill_between(h_new,gam_new0,np.full(len(h_maj),0),color='grey',alpha=1.0,zorder=1,label = 'Nugget')\n",
    "    if c1 > 0.0001:\n",
    "        plt.plot(h_new,gam_new1+gam_new0,color = 'purple',lw=1.5)\n",
    "        plt.fill_between(h_new,gam_new1+gam_new0,gam_new0,color='darkorange',alpha=1.0,zorder=1,label = 'Structure #1')\n",
    "    \n",
    "    if c2 > 0.0001:   \n",
    "        plt.plot(h_new,gam_new2+gam_new1+gam_new0,color = 'purple',lw=1.5)\n",
    "        plt.fill_between(h_new,gam_new2+gam_new1+gam_new0,gam_new1+gam_new0,color='deepskyblue',alpha=1.0,zorder=1,label='Structure #2')\n",
    "    \n",
    "    plt.plot([0,2000],[1.0,1.0],color = 'black',ls='--')\n",
    "    plt.xlabel(r'Lag Distance $\\bf(h)$, (m)')\n",
    "    plt.ylabel(r'$\\gamma \\bf(h)$')\n",
    "    if azi_tol.value < 90.0:\n",
    "        plt.title('Interpolated ' + feature + ' Variogram - Azi. ' + str(new_azimuth))\n",
    "    else: \n",
    "        plt.title('Omni Directional NSCORE ' + feature + ' Variogram ')\n",
    "        \n",
    "    if c1 > 0.0001:\n",
    "        plt.vlines(hmaj1,0,1.8,color='black',lw=1.5); \n",
    "\n",
    "    if c1 > 0.0001:      \n",
    "        plt.vlines(hmin1,0,1.8,color='red',lw=1.5)\n",
    "        \n",
    "    if c2 > 0.0001:\n",
    "        plt.vlines(hmaj2,0,1.8,color='black',lw=1.5); \n",
    "  \n",
    "    if c2 > 0.0001:      \n",
    "        plt.vlines(hmin2,0,1.8,color='red',lw=1.5)\n",
    "    \n",
    "    # plt.vlines(hmin1,0,1.8,color='black',lw=1.5); plt.vlines(hmin2,0,1.8,color='deepskyblue',lw=1.5)\n",
    "    # plt.annotate('Structure 1 Range',[hmin1-30,1.3],rotation=90.0); plt.annotate('Structure 2 Range',[hmin2-30,1.3],color='deepskyblue',rotation=90.0)\n",
    "    plt.xlim([0,1000]); plt.ylim([0,1.8])\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    \n",
    "    plt.xlim([-2000,2000]); plt.ylim([-2000,2000]); plt.xlabel('X offset (m)'); plt.ylabel('Y offset (m)')\n",
    "    plt.plot([-2000,2000],[0,0],color='grey',lw=3,zorder=1); plt.plot([0,0],[-2000,2000],color='grey',lw=3,zorder=1)\n",
    "    plt.grid(True); plt.title('2D Variogram Structures - Ranges and Geometric Anisotropy')\n",
    "    \n",
    "    if c1 > 0.0001:\n",
    "        e1 = patches.Ellipse((0, 0), hmaj1*2, hmin1*2,angle=90-azimuth, linewidth=2, fill=True,facecolor='darkorange',edgecolor='black',alpha=1.0,zorder=4)\n",
    "        plt.gca().add_patch(e1)\n",
    "    \n",
    "    if c2 > 0.0001:\n",
    "        e2 = patches.Ellipse((0, 0), hmaj2*2, hmin2*2,angle=90-azimuth, linewidth=2, fill=True,facecolor='deepskyblue',edgecolor='black',alpha=1.0,zorder=2)\n",
    "        plt.gca().add_patch(e2)\n",
    "    \n",
    "    xarr,yarr = point_pos(0, 0, hmaj1, azimuth)\n",
    "    plt.plot([0,xarr],[0,yarr],color='black',zorder=13)\n",
    "    \n",
    "    xarr2,yarr2 = point_pos(0, 0, hmaj2, azimuth)\n",
    "    plt.plot([0,xarr2],[0,yarr2],color='black',zorder=10)\n",
    "    plt.annotate('Major',[xarr2,yarr2],zorder=10)\n",
    "    \n",
    "    xarr1,yarr1 = point_pos(0, 0, hmin1, azimuth+90.0)\n",
    "    plt.plot([0,xarr1],[0,yarr1],color='red',zorder=13)\n",
    "    \n",
    "    xarr2,yarr2 = point_pos(0, 0, hmin2, azimuth+90.0)\n",
    "    plt.plot([0,xarr2],[0,yarr2],color='red',zorder=10)\n",
    "    plt.annotate('Minor',[xarr2,yarr2],zorder=10,color='red')\n",
    "    \n",
    "    xarr_new,yarr_new = point_pos(0, 0, 1200, new_azimuth)\n",
    "    plt.plot([0,xarr_new],[0,yarr_new],color='purple',zorder=10,lw=3)\n",
    "    plt.annotate('Interpolated Azimuth',[xarr_new,yarr_new],color='purple',zorder=10)\n",
    "    \n",
    "    plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=2.5, wspace=0.2, hspace=0.2)\n",
    "    plt.show()\n",
    "    \n",
    "# connect the function to make the samples and plot to the widgets    \n",
    "interactive_plot2 = widgets.interactive_output(f_make2, {'nug':nug, 'it1':it1, 'hmaj1':hmaj1, 'hmin1':hmin1, 'it2':it2, 'c2':c2, 'hmaj2':hmaj2, 'hmin2':hmin2,'new_azimuth':new_azimuth})\n",
    "interactive_plot2.clear_output(wait = True)               # reduce flickering by delaying plot updating  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(ui10, interactive_plot2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
