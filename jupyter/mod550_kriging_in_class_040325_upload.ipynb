{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Kriging for Estimation Maps\n",
    "\n",
    "#### Reidar B Bratvold, Professor, University of Stavanger\n",
    "\n",
    "Here's a simple workflow for spatial estimation with kriging. This step is ciritical for:\n",
    "\n",
    "1. Prediction away from wells, e.g. pre-drill assessments.\n",
    "2. Spatial cross validation.\n",
    "3. Spatial uncertainty modeling.\n",
    "\n",
    "First let's explain the concept of spatial estimation.\n",
    "\n",
    "#### Spatial Estimation\n",
    "\n",
    "Consider the case of making an estimate at some unsampled location, $ùëß(\\bf{u}_0)$, where $z$ is the property of interest (e.g. porosity etc.) and $ùêÆ_0$ is a location vector describing the unsampled location.\n",
    "\n",
    "How would you do this given data, $ùëß(\\bf{ùêÆ}_1)$, $ùëß(\\bf{ùêÆ}_2)$, and $ùëß(\\bf{ùêÆ}_3)$?\n",
    "\n",
    "It would be natural to use a set of linear weights to formulate the estimator given the available data.\n",
    "\n",
    "\\begin{equation}\n",
    "z^{*}(\\bf{u}) = \\sum^{n}_{\\alpha = 1} \\lambda_{\\alpha} z(\\bf{u}_{\\alpha})\n",
    "\\end{equation}\n",
    "\n",
    "We could add an unbiasedness constraint to impose the sum of the weights equal to one.  What we will do is assign the remainder of the weight (one minus the sum of weights) to the global average; therefore, if we have no informative data we will estimate with the global average of the property of interest.\n",
    "\n",
    "\\begin{equation}\n",
    "z^{*}(\\bf{u}) = \\sum^{n}_{\\alpha = 1} \\lambda_{\\alpha} z(\\bf{u}_{\\alpha}) + \\left(1-\\sum^{n}_{\\alpha = 1} \\lambda_{\\alpha} \\right) \\overline{z}\n",
    "\\end{equation}\n",
    "\n",
    "We will make a stationarity assumption, so let's assume that we are working with residuals, $y$. \n",
    "\n",
    "\\begin{equation}\n",
    "y^{*}(\\bf{u}) = z^{*}(\\bf{u}) - \\overline{z}(\\bf{u})\n",
    "\\end{equation}\n",
    "\n",
    "If we substitute this form into our estimator the estimator simplifies, since the mean of the residual is zero.\n",
    "\n",
    "\\begin{equation}\n",
    "y^{*}(\\bf{u}) = \\sum^{n}_{\\alpha = 1} \\lambda_{\\alpha} y(\\bf{u}_{\\alpha})\n",
    "\\end{equation}\n",
    "\n",
    "while satisfying the unbaisedness constraint.  \n",
    "\n",
    "#### Kriging\n",
    "\n",
    "Now the next question is what weights should we use?  \n",
    "\n",
    "We could use equal weighting, $\\lambda = \\frac{1}{n}$, and the estimator would be the average of the local data applied for the spatial estimate. This would not be very informative.\n",
    "\n",
    "We could assign weights considering the spatial context of the data and the estimate:\n",
    "\n",
    "* **spatial continuity** as quantified by the variogram (and covariance function)\n",
    "* **redundancy** the degree of spatial continuity between all of the available data with themselves \n",
    "* **closeness** the degree of spatial continuity between the avaiable data and the estimation location\n",
    "\n",
    "The kriging approach accomplishes this, calculating the best linear unbiased weights for the local data to estimate at the unknown location.  The derivation of the kriging system and the resulting linear set of equations is available in the lecture notes.  Furthermore kriging provides a measure of the accuracy of the estimate!  This is the kriging estimation variance (sometimes just called the kriging variance).\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma^{2}_{E}(\\bf{u}) = C(0) - \\sum^{n}_{\\alpha = 1} \\lambda_{\\alpha} C(\\bf{u}_0 - \\bf{u}_{\\alpha})\n",
    "\\end{equation}\n",
    "\n",
    "What is 'best' about this estimate? Kriging estimates are best in that they minimize the above estimation variance. \n",
    "\n",
    "#### Properties of Kriging\n",
    "\n",
    "Here are some important properties of kriging:\n",
    "\n",
    "* **Exact interpolator** - kriging estimates with the data values at the data locations\n",
    "* **Kriging variance** can be calculated before getting the sample information, as the kriging estimation variance is not dependent on the values of the data nor the kriging estimate, i.e. the kriging estimator is homoscedastic. \n",
    "* **Spatial context** - kriging takes into account, furthermore to the statements on spatial continuity, closeness and redundancy we can state that kriging accounts for the configuration of the data and structural continuity of the variable being estimated.\n",
    "* **Scale** - kriging may be generalized to account for the support volume of the data and estimate. We will cover this later.\n",
    "* **Multivariate** - kriging may be generalized to account for multiple secondary data in the spatial estimate with the cokriging system. We will cover this later.\n",
    "* **Smoothing effect** of kriging can be forecast. We will use this to build stochastic simulations later.\n",
    "\n",
    "#### Objective \n",
    "\n",
    "To provide hands-on experience with building subsurface modeling workflows. Python provides an excellent vehicle to accomplish this.\n",
    "\n",
    "The objective is to remove the hurdles of subsurface modeling workflow construction by providing building blocks and sufficient examples. This is not a coding class per se, but we need the ability to 'script' workflows working with numerical methods.    \n",
    "\n",
    "#### Load the required libraries\n",
    "\n",
    "The following code loads the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geostats                 # GSLIB methods convert to Python    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need some standard packages. These should have been installed with Anaconda 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                               # to set current working directory \n",
    "import numpy as np                                      # arrays and matrix math\n",
    "import pandas as pd                                     # DataFrames\n",
    "import matplotlib.pyplot as plt                         # plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing 'python -m pip install [package-name]'. More assistance is available with the respective package docs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Tabular Data\n",
    "\n",
    "Here's the command to load our comma delimited data file in to a Pandas' DataFrame object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_data = 0.2                                     # extract a fraction of data for demonstration / faster runs, set to 1.0 for homework\n",
    "\n",
    "#df = pd.read_csv(\"sample_data_MV_biased.csv\")                     # read a .csv file in as a DataFrame\n",
    "df = pd.read_csv(\"../data/sample_data_MV_biased.csv\") # load the data from Dr. Pyrcz's GitHub repository\n",
    "\n",
    "if fraction_data < 1.0:\n",
    "    df = df.sample(frac = fraction_data,replace = False,random_state = 73073) #`random_state = 73073` ensures reproducibility\n",
    "df = df.reset_index() #ensuring a continuous index\n",
    "df = df.iloc[:,2:] #remove the first two columns\n",
    "\n",
    "df['LogPerm'] = np.log(df['Perm'].values)\n",
    "\n",
    "df.head()                                               # we could also use this command for a table preview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Statistics\n",
    "\n",
    "Let's look at summary statistics for all facies combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()                          # summary table of all facies combined DataFrame statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)                                        # plot original sand and shale porosity histograms\n",
    "plt.hist(df['Porosity'], facecolor='darkorange',bins=np.linspace(0.0,0.25,1000),histtype=\"stepfilled\",alpha=0.8,density=True,cumulative=True,edgecolor='black',label='Original')\n",
    "plt.xlim([0.05,0.25]); plt.ylim([0,1.0])\n",
    "plt.xlabel('Porosity (fraction)'); plt.ylabel('Frequency'); plt.title('Porosity')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)                                        # plot nscore transformed sand and shale histograms\n",
    "plt.hist(df['Perm'], facecolor='darkorange',bins=np.linspace(0.0,1000.0,100000),histtype=\"stepfilled\",alpha=0.8,density=True,cumulative=True,edgecolor='black',label='Original')\n",
    "plt.xlim([0.0,1000.0]); plt.ylim([0,1.0])\n",
    "plt.xlabel('Permeability (mD)'); plt.ylabel('Frequency'); plt.title('Permeability')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe from the CDFs that the porosity distribution is 'Gaussian-like' in shape, while the permeability distribution is 'lognormal-like'.  They both look well behaved.\n",
    "\n",
    "#### Calculating the Representative Mean with Declustering\n",
    "\n",
    "For brevity we will omit data declustering from this workflow. We will assume declustered means for the porosity and permeability to apply with simple kriging.\n",
    "\n",
    "#### Location Maps\n",
    "\n",
    "Let's plot the location maps of porosity and permeability for all facies. We will also include a cross plot of permeability vs. porosity colored by facies to aid with comparison in spatial features between the porosity and permeability data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location map function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locmap_st(df, x_col, y_col, feature_col, xmin, xmax, ymin, ymax, \n",
    "              vmin, vmax, title, xlabel, ylabel, cmap=\"inferno\"):\n",
    "    \"\"\"\n",
    "    Plots a spatial location map of a feature using a scatter plot in the current subplot.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe containing spatial data.\n",
    "    x_col, y_col : str\n",
    "        Column names for X and Y coordinates.\n",
    "    feature_col : str\n",
    "        Column name for the feature to be visualized.\n",
    "    xmin, xmax : float\n",
    "        Minimum and maximum values for the X-axis.\n",
    "    ymin, ymax : float\n",
    "        Minimum and maximum values for the Y-axis.\n",
    "    vmin, vmax : float\n",
    "        Minimum and maximum values for the color scale.\n",
    "    title : str\n",
    "        Title of the plot.\n",
    "    xlabel, ylabel : str\n",
    "        Labels for the X and Y axes.\n",
    "    cmap : str (default=\"inferno\")\n",
    "        Colormap for visualization.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None (displays the plot)\n",
    "    \"\"\"\n",
    "\n",
    "    ax = plt.gca()  # Get the current subplot\n",
    "    scatter = ax.scatter(\n",
    "        df[x_col], df[y_col], c=df[feature_col],\n",
    "        cmap=cmap, edgecolors=\"black\", vmin=vmin, vmax=vmax\n",
    "    )\n",
    "\n",
    "    # Add color bar\n",
    "    cbar = plt.colorbar(scatter, ax=ax, shrink=0.8)\n",
    "    cbar.set_label(feature_col)\n",
    "\n",
    "    # Set axis labels and limits\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = 0.0; xmax = 1000.0               # range of x values\n",
    "ymin = 0.0; ymax = 1000.0               # range of y values\n",
    "\n",
    "xsiz = 10; ysiz = 10                    # cell size\n",
    "nx = 100; ny = 100                      # number of cells\n",
    "xmn = 5; ymn = 5                        # grid origin, location center of lower left cell\n",
    "\n",
    "cmap = plt.cm.plasma                    # color map\n",
    "\n",
    "plt.subplot(121)\n",
    "locmap_st(df, 'X', 'Y', 'Porosity', 0, 1000, 0, 1000, 0, 0.25,\n",
    "          'Porosity - All Facies', 'X (m)', 'Y (m)', cmap)\n",
    "\n",
    "plt.subplot(122)\n",
    "locmap_st(df, 'X', 'Y', 'Perm', 0, 1000, 0, 1000, 0, 1000,\n",
    "          'Permeability - All Facies', 'X (m)', 'Y (m)', cmap)\n",
    "\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.0, wspace=0.3, hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kriging for Porosity and Permeability Maps\n",
    "\n",
    "Now let's try some kriging with the continuous properties. For this workflow we will demonstrate a cookie-cutter approach.  The steps are:\n",
    "\n",
    "1. model the facies, sand and shale, probabilities with indicator kriging\n",
    "2. model the porosity for sand and shale separately and exhaustively, i.e. at all locations in the model\n",
    "3. model the permeability for sand and shale separately and exhaustively, i.e. at all locations in the model\n",
    "4. assign sand and shale locations based on the probabilities from step 1 \n",
    "5. combine the porosity and permeability from sand and shale regions together\n",
    "\n",
    "Limitations of this Workflow:\n",
    "\n",
    "* kriging is too smooth, the spatial continuity is too high\n",
    "* kriging does not reproduce the continuous property distributions\n",
    "* we are not accounting for the correlation between porosity and permeability \n",
    "\n",
    "We will correct these issues when we perform simulation later.\n",
    "\n",
    "We need to add a couple of parameters and assume a porosity variogram model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skmean_por = 0.10; skmean_perm = 65.0      # simple kriging mean (used if simple kriging is selected below)\n",
    "ktype = 0                                  # kriging type, 0 - simple, 1 - ordinary\n",
    "radius = 300                               # search radius for neighbouring data\n",
    "nxdis = 1; nydis = 1                       # number of grid discretizations for block kriging (not tested)\n",
    "ndmin = 0; ndmax = 40                      # minimum and maximum data for an estimate\n",
    "por_min = 0.0; por_max = 0.3               # minimum property value\n",
    "perm_min = 0.0; perm_max = 1000.0          # minimum property value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Kriging Estimation Map of Porosity\n",
    "\n",
    "Let's start with spatial estimates of porosity and permeability with all facies combined. We will also look at the kriging estimation variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also not use cyclicity for now, as we are just getting started.  \n",
    "\n",
    "* Let's build a reasonable model to the sill.\n",
    "\n",
    "##### `make_variogram function`\n",
    "\n",
    "We use the make_variogram function to make a variogram model \n",
    "\n",
    "* a dictionary for compact storage of the variogram model parameters to pass into plotting (below), kriging and simulation methods \n",
    "\n",
    "The variogram model parameter include:\n",
    "\n",
    "* **nug** - nugget effect contribution to sill\n",
    "* **nst** - number of nested structures (1 or 2)\n",
    "* **it** - type for this nested structure (1 - spherical, 2 - exponential, 3 - Gaussian)\n",
    "* **c** - contribution of each nested structure (contributions + nugget must sum to the sill)\n",
    "* **ang** - the azimuth for this nested structure of the major direction, the minor is orthogonal\n",
    "* **hmaj** - the range for this nested structure in the major direction\n",
    "* **hmin** - the range for this nested structure in the minor direction\n",
    "\n",
    "We increment it, c, ang, hmaj, and hmin for the 1st and 2nd structures\n",
    "\n",
    "* for only 1 structure plus optional nugget, omit the 2nd structure parameters and they will default to $cc2 = 0$, no contribution to the model\n",
    "\n",
    "Here's my model:\n",
    "\n",
    "```p\n",
    "nug = 0.0; nst = 2\n",
    "it1 = 1; cc1 = 0.6; azi1 = 45; hmaj1 = 350; hmin1 = 350                # first structure\n",
    "it2 = 1; cc2 = 0.4; azi2 = 45; hmaj2 = 9999.9; hmin2 = 400             # second structure\n",
    "```\n",
    "\n",
    "Some comments on our model:\n",
    "\n",
    "* we model to the sill of 1.0, since we applied the normal score transform ($nug + cc1 + cc2 = 1.0$)\n",
    "\n",
    "* we used 2 spherical structures to capture zontal anisotropy in the 045 azimuth\n",
    "\n",
    "* since the experimental variogram exceeds the sill with trend or cyclicity we could have attempted trend modeling and then worked with the residual, but we will not do this for workflow brevity and simplicity\n",
    "\n",
    "We input these model parameters to make a variogram model dictionary with the make_variogram function as follows:\n",
    "\n",
    "```p\n",
    "vario = make_variogram(nug,nst,it1,cc1,azi1,hmaj1,hmin1,it2,cc2,azi2,hmaj2,hmin2)\n",
    "```\n",
    "\n",
    "##### vmodel function\n",
    "\n",
    "To plot the variogram we use the vmodel function to project the model in the major and minor directions\n",
    "\n",
    "The inputs for vmodel are:\n",
    "\n",
    "* **nlag** - the number of points along the variogram to calculate for the projection\n",
    "\n",
    "* **xlag** - the size of a lag for the projection\n",
    "\n",
    "* **azm** - the direction of the projection in azimuth (this is all we need since we are working in 2D)\n",
    "\n",
    "* **vario** - the variogram model dictionary from the make_variogram function (above)\n",
    "\n",
    "Note: this function is just for visualization by projecting the variogram model in a direction, so the convention is to use a very small **xlag** and large **nlag** for a high resolution display of the variogram model\n",
    "\n",
    "The outputs from the vmodel program include:\n",
    "\n",
    "* **index** - the lag number for the projection\n",
    "\n",
    "* **lag distance** - the distance offset along the projection (the **h** in the variogram plot)\n",
    "\n",
    "* **variogram** - the variogram value at the lag distance for the projection (the $\\gamma$(**h**) in the variogram plot)\n",
    "\n",
    "* **covariance function** - the covariance function at the lag distance for the projection (for the C(**h**) plot)\n",
    "\n",
    "* **correlogram** - the correlogram at the lag distance for the projection (for the $\\rho$(**h**) plot)\n",
    "\n",
    "We have 2 structures and no nugget effect.  We needed the 2nd structure to capture the zonal anisotropy in the 045 direction.  Let's calculate the variogram model in these directions and plot them with the experimental variograms.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_variogram(nug, nst, it1, c1, ang1, hmaj1, hmin1, it2=None, c2=None, ang2=None, hmaj2=None, hmin2=None):\n",
    "    \"\"\"\n",
    "    Creates a variogram model structure for use in variogram simulations.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    nug : float\n",
    "        Nugget effect.\n",
    "    nst : int\n",
    "        Number of nested structures (1 or 2).\n",
    "    it1 : int\n",
    "        Variogram type for first structure (1=Spherical, 2=Exponential, 3=Gaussian, 4=Power).\n",
    "    c1 : float\n",
    "        Sill contribution of first structure.\n",
    "    ang1 : float\n",
    "        Major azimuth angle for first structure.\n",
    "    hmaj1 : float\n",
    "        Major range for first structure.\n",
    "    hmin1 : float\n",
    "        Minor range for first structure.\n",
    "    it2 : int, optional\n",
    "        Variogram type for second structure (if applicable).\n",
    "    c2 : float, optional\n",
    "        Sill contribution of second structure.\n",
    "    ang2 : float, optional\n",
    "        Major azimuth angle for second structure.\n",
    "    hmaj2 : float, optional\n",
    "        Major range for second structure.\n",
    "    hmin2 : float, optional\n",
    "        Minor range for second structure.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Variogram model dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    vario = {\n",
    "        \"nug\": nug,\n",
    "        \"nst\": nst,\n",
    "        \"it1\": it1,\n",
    "        \"cc1\": c1,\n",
    "        \"azi1\": ang1,\n",
    "        \"hmaj1\": hmaj1,\n",
    "        \"hmin1\": hmin1,\n",
    "    }\n",
    "\n",
    "    if nst == 2:\n",
    "        vario.update({\n",
    "            \"it2\": it2,\n",
    "            \"cc2\": c2,\n",
    "            \"azi2\": ang2,\n",
    "            \"hmaj2\": hmaj2,\n",
    "            \"hmin2\": hmin2,\n",
    "        })\n",
    "\n",
    "    return vario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to plot 2D probability map with overlaid data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def locpix_st(array, xmin, xmax, ymin, ymax, xsiz, vmin, vmax, df, x_col, y_col, feature_col, \n",
    "              title, xlabel, ylabel, cbar_label, cmap=\"inferno\"):\n",
    "    \"\"\"\n",
    "    Plots a 2D categorical probability map with overlaid data points.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    array : np.ndarray\n",
    "        2D grid of values to plot.\n",
    "    xmin, xmax : float\n",
    "        X-axis extent.\n",
    "    ymin, ymax : float\n",
    "        Y-axis extent.\n",
    "    xsiz : float\n",
    "        Cell size for spatial resolution.\n",
    "    vmin, vmax : float\n",
    "        Color scale limits.\n",
    "    df : pd.DataFrame\n",
    "        Dataframe containing spatial points.\n",
    "    x_col, y_col : str\n",
    "        Column names for X and Y coordinates.\n",
    "    feature_col : str\n",
    "        Column name for the feature (facies or probability).\n",
    "    title : str\n",
    "        Plot title.\n",
    "    xlabel, ylabel : str\n",
    "        Labels for the X and Y axes.\n",
    "    cbar_label : str\n",
    "        Label for the colorbar.\n",
    "    cmap : str, optional (default=\"inferno\")\n",
    "        Colormap for visualization.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None (displays the plot).\n",
    "    \"\"\"\n",
    "\n",
    "    extent = [xmin, xmax, ymin, ymax]\n",
    "\n",
    "    # Fix rotation issue: Flip vertically to match coordinate system\n",
    "    array = np.flipud(array)\n",
    "    array = np.where(np.isnan(array), np.nan, array)  # Preserve NaNs\n",
    "\n",
    "    plt.imshow(array, extent=extent, origin=\"lower\", vmin=vmin, vmax=vmax, cmap=cmap, aspect=\"auto\")\n",
    "\n",
    "    # Add data points with yellow color and black edges\n",
    "    plt.scatter(df[x_col], df[y_col], color=\"yellow\", edgecolors=\"black\", s=20)\n",
    "\n",
    "    # Add color bar\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(cbar_label)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for plotting 2D pixel map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pixelplt_st(array, xmin, xmax, ymin, ymax, step, vmin, vmax, title, xlabel, ylabel, cbar_label, cmap=\"inferno\"):\n",
    "    \"\"\"\n",
    "    Plots a 2D pixel map using `imshow()` with a colorbar.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    array : np.ndarray\n",
    "        2D array to plot.\n",
    "    xmin, xmax : float\n",
    "        X-axis extent.\n",
    "    ymin, ymax : float\n",
    "        Y-axis extent.\n",
    "    step : float\n",
    "        Resolution step size.\n",
    "    vmin, vmax : float\n",
    "        Color scale limits.\n",
    "    title : str\n",
    "        Title of the plot.\n",
    "    xlabel, ylabel : str\n",
    "        Axis labels.\n",
    "    cbar_label : str\n",
    "        Label for the colorbar.\n",
    "    cmap : str (default=\"inferno\")\n",
    "        Colormap for visualization.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None (displays the plot).\n",
    "    \"\"\"\n",
    "\n",
    "    extent = [xmin, xmax, ymin, ymax]\n",
    "    \n",
    "    plt.imshow(array, extent=extent, origin=\"lower\", vmin=vmin, vmax=vmax, cmap=cmap, aspect=\"auto\")\n",
    "\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(cbar_label)\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`kb2d` in GSLIB (2D Kriging)**\n",
    "\n",
    "## **What is `kb2d`?**\n",
    "The `kb2d` function (replicated from GSLIB) is used for **2D Kriging**‚Äîspecifically, it performs **ordinary or simple kriging** in two dimensions.\n",
    "\n",
    "---\n",
    "\n",
    "## **Function Purpose**\n",
    "`kb2d` stands for **Kriging Bivariate in 2D**.  \n",
    "It estimates unknown values at unsampled locations based on known values using **spatial interpolation** techniques.\n",
    "\n",
    "---\n",
    "\n",
    "## **General Syntax of `kb2d` in GSLIB**\n",
    "\n",
    "# **GeostatsPy `kb2d` Function Argument List**\n",
    "\n",
    "The `kb2d` function in **GeostatsPy** performs **2D Kriging interpolation** over a **structured spatial grid**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Function Signature**\n",
    "```python\n",
    "por_kmap, por_vmap = geostats.kb2d(df, 'X', 'Y', 'Porosity', por_min, por_max, \n",
    "                                   nx, xmn, xsiz, ny, ymn, ysiz, \n",
    "                                   nxdis, nydis, ndmin, ndmax, radius, \n",
    "                                   ktype, skmean_por, por_vario)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Function Arguments**\n",
    "| **Argument** | **Description** |\n",
    "|-------------|----------------|\n",
    "| `df`        | **Pandas DataFrame** containing spatial data. |\n",
    "| `x_col`     | Column name in `df` for **X-coordinates** of known points. |\n",
    "| `y_col`     | Column name in `df` for **Y-coordinates** of known points. |\n",
    "| `z_col`     | Column name in `df` for **values to be interpolated** (e.g., Porosity). |\n",
    "| `zmin`      | **Minimum value** of the property (for scaling/visualization). |\n",
    "| `zmax`      | **Maximum value** of the property (for scaling/visualization). |\n",
    "| `nx`        | **Number of grid cells** in the X-direction. |\n",
    "| `xmn`       | **Minimum X-coordinate** (origin of the grid in X-direction). |\n",
    "| `xsiz`      | **Grid cell size** in the X-direction. |\n",
    "| `ny`        | **Number of grid cells** in the Y-direction. |\n",
    "| `ymn`       | **Minimum Y-coordinate** (origin of the grid in Y-direction). |\n",
    "| `ysiz`      | **Grid cell size** in the Y-direction. |\n",
    "| `nxdis`     | **Number of discretization points** in X (for block kriging). |\n",
    "| `nydis`     | **Number of discretization points** in Y (for block kriging). |\n",
    "| `ndmin`     | **Minimum number of neighboring points** required for kriging. |\n",
    "| `ndmax`     | **Maximum number of neighboring points** used for kriging. |\n",
    "| `radius`    | **Search radius** for selecting neighboring data points. |\n",
    "| `ktype`     | **Kriging type**: $0$ for **Simple Kriging**, $1$ for **Ordinary Kriging**. |\n",
    "| `skmean`    | **Mean value for Simple Kriging** ($\\bar{Z}$). Ignored if `ktype=1`. |\n",
    "| `vario`     | **Variogram model** (created using `geostats.make_variogram`). |\n",
    "\n",
    "---\n",
    "\n",
    "## **Kriging Type Explanation**\n",
    "- **Simple Kriging ($ktype=0$)** assumes a **known global mean**:\n",
    "  $$ Z^*(x) = \\bar{Z} + \\sum_{i=1}^{n} \\lambda_i (Z(x_i) - \\bar{Z}) $$\n",
    "  where:\n",
    "  - $ Z^*(x) $ is the estimated value at an unknown location.\n",
    "  - $ \\bar{Z} $ is the known global mean.\n",
    "  - $ Z(x_i) $ are the known values at sampled locations.\n",
    "  - $ \\lambda_i $ are the kriging weights.\n",
    "\n",
    "- **Ordinary Kriging ($ktype=1$)** assumes an **unknown local mean**:\n",
    "  $$ Z^*(x) = \\sum_{i=1}^{n} \\lambda_i Z(x_i) $$\n",
    "  with the constraint:\n",
    "  $$ \\sum_{i=1}^{n} \\lambda_i = 1 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the variogram model in this example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "por_vario = make_variogram(nug=0.0,nst=1,it1=1,c1=1.0,ang1=45,hmaj1=300,hmin1=300) # porosity variogram\n",
    "por_vario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "- The spherical variogram (it1=1) is used.\n",
    "\n",
    "- There is no nugget effect (nug=0.0), meaning no measurement error or micro-scale variability.\n",
    "\n",
    "- The spatial correlation extends up to 300 meters in both the major (hmaj1=300) and minor (hmin1=300) directions.\n",
    "\n",
    "- The direction of maximum continuity is at 45¬∞ azimuth.\n",
    "\n",
    "This means that data points closer than 300 meters are expected to have a strong spatial correlation, while those farther than 300 meters are uncorrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Kriged porosity map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "por_vario = make_variogram(nug=0.0,nst=1,it1=1,c1=1.0,ang1=45,hmaj1=300,hmin1=300) # porosity variogram\n",
    "\n",
    "por_kmap, por_vmap = geostats.kb2d(df,'X','Y','Porosity',por_min,por_max,nx,xmn,xsiz,ny,ymn,ysiz,nxdis,nydis,\n",
    "         ndmin,ndmax,radius,ktype,skmean_por,por_vario)\n",
    "\n",
    "plt.subplot(121)\n",
    "locpix_st(por_kmap,xmin,xmax,ymin,ymax,xsiz,0.0,0.25,df,'X','Y','Porosity','Simple Kriging Estimates and Data','X(m)','Y(m)','Porosity (%)',cmap)\n",
    "\n",
    "plt.subplot(122)\n",
    "pixelplt_st(por_vmap,xmin,xmax,ymin,ymax,xsiz,0.0,1.0,'Kriging Variance','X(m)','Y(m)',r'Porosity ($\\%^2$)',cmap)\n",
    "\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.0, wspace=0.3, hspace=0.3); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Some observations:**\n",
    "\n",
    "* see the smooth kriging estimates, and note the estimated values at distance greater than the variogram range from any data approach the global mean. \n",
    "\n",
    "* See the kriging variance map and observe the impact of variogram range and potential anisotropy.\n",
    "\n",
    "### Simple Kriging Estimation Map of Permeability\n",
    "\n",
    "Now let's calculate the kriging estimation map for permeability\n",
    "\n",
    "* Confidence is highest near data points and lowest where interpolation is needed.\n",
    "\n",
    "* More data points = lower uncertainty.\n",
    "\n",
    "* If important decisions depend on low-variance estimates, more sampling may be needed in high-variance areas.\n",
    "\n",
    "* note, due to the strong positive skew of permeability and the kriging screening effect, permeability estimates may be very small or even negative. We truncate the map to clean this up\n",
    "\n",
    "* we will apply the log transformation to improve the visualization. We could also plot in log scale, but this is not very convenient with MatPlotLib. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Kriged permeability map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_vario = make_variogram(nug=0.0,nst=1,it1=1,c1=1.0,ang1=45,hmaj1=300,hmin1=300) # permeability variogram\n",
    "\n",
    "perm_kmap, perm_vmap = geostats.kb2d(df,'X','Y','Perm',perm_min,perm_max,nx,xmn,xsiz,ny,ymn,ysiz,nxdis,nydis,\n",
    "          ndmin,ndmax,radius,ktype,skmean_perm,perm_vario)\n",
    "\n",
    "perm_kmap[perm_kmap < 0.0001] = 0.0001           # remove small and negative values due to strong positive skew and negative kriging weights\n",
    "\n",
    "plt.subplot(131)\n",
    "locpix_st(perm_kmap,xmin,xmax,ymin,ymax,xsiz,0.0,1000,df,'X','Y','Perm','Simple Kriging Estimates and Data','X(m)','Y(m)','Permeability (mD)',cmap)\n",
    "\n",
    "logperm_kmap = np.log(perm_kmap)\n",
    "\n",
    "plt.subplot(132)\n",
    "locpix_st(logperm_kmap,xmin,xmax,ymin,ymax,xsiz,0.0,10.0,df,'X','Y','LogPerm','Simple Kriging Log(Estimates and Data)','X(m)','Y(m)','Log Permeability (mD)',cmap)\n",
    "\n",
    "plt.subplot(133)\n",
    "pixelplt_st(perm_vmap,xmin,xmax,ymin,ymax,xsiz,0.0,1.0,'Kriging Variance','X(m)','Y(m)',r'Permeability ($mD^2$)',cmap)\n",
    "\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=3.0, top=1.0, wspace=0.3, hspace=0.3); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Some observations**\n",
    "\n",
    "The maps provide insights into **spatial trends** and **uncertainty** in permeability estimation. Below is an interpretation of each map.\n",
    "\n",
    "---\n",
    "\n",
    "## **Left: Simple Kriging Estimates and Data**\n",
    "- This map displays the **kriged permeability estimates** based on the available data.\n",
    "- **Yellow dots** represent the **original sample points** (measured permeability values).\n",
    "- The **color gradient** represents the interpolated permeability values:\n",
    "  - **Bright areas (yellow-white)** indicate **higher permeability**.\n",
    "  - **Dark areas (blue-purple)** indicate **lower permeability**.\n",
    "- The **spatial pattern of high permeability regions** suggests:\n",
    "  - A **clustered trend** of high permeability near **(x ‚âà 300‚Äì400, y ‚âà 600‚Äì800)**.\n",
    "  - Smooth interpolation extends these values into unsampled regions.\n",
    "\n",
    "### **Inference:**  \n",
    "- **Permeability varies spatially** but follows a structured pattern.  \n",
    "- **More data points = More reliable estimates** (regions with more yellow dots are better constrained).  \n",
    "\n",
    "---\n",
    "\n",
    "## **Middle: Simple Kriging Log(Estimates and Data)**\n",
    "- This map applies a **log transformation** to the permeability estimates.\n",
    "- Log transformations **reduce the influence of extreme values**, making **spatial variations more visible**.\n",
    "- The **spatial pattern remains similar**, but:\n",
    "  - Some **dark holes** indicate **areas of poor data coverage**, leading to **extrapolation uncertainty**.\n",
    "\n",
    "### **Inference:**  \n",
    "- The log-transformed map highlights **subtle spatial variations**.  \n",
    "- **Regions with sharp permeability contrasts** become more visible.  \n",
    "- Large **dark zones** could indicate **areas with no local data, reducing confidence in estimates**.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Right: Kriging Variance (Uncertainty Map)**\n",
    "- This map represents the **kriging variance**, which measures **prediction uncertainty**.\n",
    "- **Bright yellow regions** = **High uncertainty (low data support)**.\n",
    "- **Dark purple regions** = **Low uncertainty (high data density and strong correlation)**.\n",
    "- We observe **high uncertainty in areas with sparse data coverage**.\n",
    "\n",
    "### **Inference:**  \n",
    "- **Uncertainty is lowest near sample points** (dark spots around yellow dots).  \n",
    "- **Uncertainty increases where kriging relies heavily on extrapolation**.  \n",
    "- **Higher variance along grid edges** suggests **poorly constrained predictions**.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways**\n",
    "**Data-Rich Areas:**  \n",
    "- Predictions are **more reliable** where sample points exist.  \n",
    "\n",
    "**Data-Sparse Areas:**  \n",
    "- High uncertainty occurs **where kriging relies heavily on extrapolation**.\n",
    "\n",
    "**Usefulness of the Log Map:**  \n",
    "- Helps interpret regions with extreme permeability values.\n",
    "\n",
    "**Next Steps:**  \n",
    "- Consider **adding more sample points** in high-variance areas to improve prediction accuracy.  \n",
    "- Use **cross-validation** to test how well kriging estimates match observed data.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinary Kriging Estimation Map of Porosity\n",
    "\n",
    "Let's try ordinary kriging and compare the results to simple kriging.\n",
    "\n",
    "* we shorten the variogram model range to exagerate the difference between simple and ordinary kriging, i.e., with esitmates outside variogram range from any data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "por_vario2 = make_variogram(nug=0.0,nst=1,it1=1,c1=1.0,ang1=45,hmaj1=50,hmin1=50) # porosity variogram\n",
    "\n",
    "por_SK_kmap, por_vmap = geostats.kb2d(df,'X','Y','Porosity',por_min,por_max,nx,xmn,xsiz,ny,ymn,ysiz,nxdis,nydis,\n",
    "         ndmin,ndmax,radius,0,skmean_por,por_vario2)\n",
    "\n",
    "por_OK_kmap, por_OK_vmap = geostats.kb2d(df,'X','Y','Porosity',por_min,por_max,nx,xmn,xsiz,ny,ymn,ysiz,nxdis,nydis,\n",
    "         ndmin,ndmax,radius,1,skmean_por,por_vario2)\n",
    "\n",
    "plt.subplot(121)\n",
    "locpix_st(por_SK_kmap,xmin,xmax,ymin,ymax,xsiz,0.0,0.25,df,'X','Y','Porosity','Simple Kriging Estimates and Data','X(m)','Y(m)','Porosity (%)',cmap)\n",
    "\n",
    "plt.subplot(122)\n",
    "locpix_st(por_OK_kmap,xmin,xmax,ymin,ymax,xsiz,0.0,0.25,df,'X','Y','Porosity','Ordinary Kriging Estimates and Data','X(m)','Y(m)','Porosity (%)',cmap)\n",
    "\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.0, wspace=0.3, hspace=0.3); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Take aways - Simple Kriging vs. Ordinary Kriging**\n",
    "\n",
    "## **Simple Kriging Estimates**\n",
    "\n",
    "- Influenced by the global mean.\n",
    "\n",
    "- Porosity estimates stay close to the assumed mean except where data exists.\n",
    "\n",
    "\n",
    "## **Ordinary Kriging Estimates**\n",
    "\n",
    "- The estimated values appear more locally adaptive.\n",
    "\n",
    "- Unlike SK, OK does not assume a global mean.\n",
    "\n",
    "- More spatial variability is preserved, especially in data-sparse regions.\n",
    "\n",
    "- Porosity values change more dynamically, rather than being pulled toward a global mean.\n",
    "\n",
    "## **Inference (SK vs. OK):**\n",
    "\n",
    "- Simple Kriging (SK) assumes a known global mean, leading to smoother predictions.\n",
    "\n",
    "- Ordinary Kriging (OK) assumes a locally varying mean, allowing for more localized variations in porosity.\n",
    "\n",
    "- If you lack prior knowledge of a global mean, Ordinary Kriging is more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "\n",
    "This was a basic demonstration of spatial estimation. Much more could be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
